---
title: "Raspando os dados com R"
description: |
  Para facilitar nossa vida!
date: "`r Sys.Date()`"
output: 
  distill::distill_article:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
xaringanExtra::use_panelset()
library(magrittr)
```

# 5. Web Scraping como uma ferramenta

Antes de iniciarmos nossos códigos, nunca é demais salientar que esse texto 
trata-se de uma introdução.
Coletar dados da *web* pode ser uma tarefa realmente árdua e desafiadora, pois
os sites podem dificultar o acesso de diversas formas.

Abordaremos situações simples, onde o web scraping realmente é usado como uma
ferramenta para aumentar a produtividade do professor, reduzindo seu tempo em
muitas situações que frequentemente aparecem na vida profissional.

Uma outra coisa impotante, antes de iniciarmos a prática, é sempre termos em 
mente que nossos códigos são estabelecidos em certo momento temporal, ou seja,
o código funciona "naquele momento" e esperamos que continue assim.

Mas, sites podem mudar e, consequentemente, o nosso código pode "quebrar".
Por isso, dependendo da época em que você esteja lendo esse texto, as coisas 
podem estar bem diferentes.
A idéia é você entender os fundamentos e aplicar numa situação particular que
deseja.

## 5.1 Ética no Web Scraping

Quando usamos um programa para extrair dados de um site, estamos fazendo requisições
ao servidor daquele site.
Obviamente, muitas requisições podem tornar lento um site e isso não é desejado 
por seus mantenedores.

Essa é uma das razões para que alguns sites **restrinjam** o acesso em determinada
área, ou da totalidade do site!

Por isso, conhecer as permissões de cada site é importantíssimo numa possível
"raspagem" de dados.

> Sempre leia as permissões do site, antes de iniciar qualquer atividade de web
scraping.

Uma das formas de sabermos se um site permite a raspagem é verificando os 
**robots.txt**.

Para isso, na url de cada site, ao final da mesma, digite: "/robots.txt".

Essa é uma condição necessária, mas não suficiente.
Alguns sites colocam restrições não nos robots.txt, mas em alguma seção do mesmo.
Por isso, se não aparecer nada no texto do robots.txt, pode ser que o site não o 
tenha.
Então, deve-se procurar informações sobre raspagem de dados no próprio site!

Por exemplo, no site da ANPMat (Associação Nacional dos Professores de Matemática
na Educação Básica), a saber:

<p align='center'>
  <a src='https://anpmat.org.br/'> https://anpmat.org.br/ </a>
</p>

Podemos verificar se "robôs" podem acessá-lo.
Para isso, digitamos:

<p align='center'>
  <a src='https://anpmat.org.br/robots.txt'> https://anpmat.org.br/robots.txt </a>
</p>

A seguinte mensagem aparece:

```{r, eval=FALSE}
# XML Sitemap & Google News version 5.2.7 - https://status301.net/wordpress-plugins/xml-sitemap-feed/
Sitemap: https://anpmat.org.br/sitemap.xml

User-agent: *
Disallow: /wp-admin/
Allow: /wp-admin/admin-ajax.php

Sitemap: https://anpmat.org.br/wp-sitemap.xml

```

Veja que a seção "wp-admin" não está hailitada para web scraping.

Uma outra questão, é quando envolve a raspagem de dados em muitas páginas.
Mas, o pacote [polite](https://dmi3kno.github.io/polite/) pode ser usado junto 
com o `rvest` e solucionar esse problema, visto que esse pacote respeitará as
requisições feitas em cada site.

Bom ... agora vamos à prática!

## 5.2 Fazendo download de vários arquivos

Uma das situações que comumente nos deparamos em nossa profissão é fazermos 
downloads de bons materiais disponíveis gratuitamente na internet.
Porém, se a lista de download for relativamente grande, fazer isso manualmente,
ou seja, clicar em cada um deles e salvar num determinado local ... pode ser 
tedioso.

Mas ... graças a Deus, exite o R!

### 5.2.1 Arquivos de texto

Para exemplificar o *dowload* de vários arquivos de texto, vamos acessar o link
da página do *Laboratório de Estatística Computacional -- LEC*, da UESC.
Na seção "Material Didático/R", estão disponíveis *scripts*, em R, sobre diversos
temas, dentre outras coisas.

> **O que desejamos fazer?** . Essa pergunta sempre deve ser nosso norte, antes de 
  iniciarmos a raspagem dos dados!

Nosso objetivo, nesse exemplo, é fazer o *download* dos 18 arquivos que se 
encontram na seção "Introdução ao R (tutor: prof. José Cláudio Faria)", 
etiquetados como: "CIR.00_apresentação", "CIR.01_gerenciamentos_pacotes", ..., 
"CIR.17aplicações".
Como na figura abaixo:

```{r, fig.align='center', echo=FALSE}
knitr::include_graphics("img/uesc-pro_seta.png")
```

Agora, vamos atribuir à variável **url_uesc** o link da url em questão:

```{r}
url_uesc <- "https://lec.pro.br/avale-es/r"
```

E, à variável **site_uesc** o html extraído com a função `read_html()`, do pacote
`rvest`:

```{r}
site_uesc <- rvest::read_html(url_uesc)
```

Estamos prontos para a manipulação desses dados!

Com a ajuda do *SelectorGadget*, selecionamos o elemento que desejamos raspar e,
depois, fazemos os ajustes necessários (até ficar em amarelo o que desejamos, da
menor forma possível).

Abaixo, o código mostra que o elemento CCS "li:nth-child(2) h5+ ul a"

```{r}
site_uesc |> 
  rvest::html_elements("li:nth-child(2) h5+ ul a")
```

Obviamemte o elemento CCS pode mudar um pouco.
Dependenderá muito da seleção que você fez.
Por exemplo, se não fossem feitos os ajustes, a *tag* "a" serviria normalmente.
O problema dessa abordadem é que existem muitas outras *tags* "a" espalhadas pelo
site que não nos interessa.

Feito isso, precisamos extrair desses elementos os *links* de cada arquivo.
O atributto "href" nos dará isso.
Então, basta usarmos a função `rvest::html_attr("href")`:

```{r}
site_uesc |> 
  rvest::html_elements("li:nth-child(2) h5+ ul a") |> 
  rvest::html_attr("href")
```

Antes de prosseguirmos note um certo "padrão" que aparece nos links desejados.
Por exemplo, antes do nome dos arquivos que desejamos extrair, podemos observar
a repetição dos caracteres "**CIR.**".
Isso seria importante se a nossa seleção abrangesse mais arquivos além do exposto.
Se isso ocorresse, poderíamos usar uma função do pacote `stringr` para 
selecionarmos esse padrão específico: **stringr::str_subset("CIR.")**.
Mas, como a nossa seleção foi bem exitosa, afinal extraiu o que desejávamos, não
usaremos essa função em nosso *script*.

Nesso momento, também é importante notar que, se clicarmos diretamente em algum 
dos links desejados, aparecerá uma parte da *url*, a saber, "https://lec.pro.br", 
que não se encontra no conjunto acima listado.

Para inserirmos essa parte da url, ANTES dos itens da lista acima, usaremos a
função **str_c()**, do pacote `stringr`.
Veja o código abaixo (note que usamos o pipe `%>%`, pois passaremos o argumento
anterior na SEGUNDA posição):

```{r}
site_uesc |> 
  rvest::html_elements("li:nth-child(2) h5+ ul a") |> 
  rvest::html_attr("href") %>% 
  stringr::str_c("https://lec.pro.br", .)
```

O que precisamos, agora, é fazer o *download*.
Antes, porém, vamos salvar na variável **links_uesc** a lista extraída acima.

```{r}
links_uesc <- site_uesc |> 
  rvest::html_elements("li:nth-child(2) h5+ ul a") |> 
  rvest::html_attr("href") %>% 
  stringr::str_c("https://lec.pro.br", .)
```

Estamos quase prontos para fazermos o *download* dos arquivos.
Entretanto, vamos organizar as coisas ...

Por exemplo, quando fizermos o *download*, qual será o nome dos arquivos?
Poderíamos criar uma lista com o nome que desejarmos, mas, por hora, vamos deixar
os nomes que já estão no final de cada link, pois possui certo padrão: 
  
  - `CIR.n_nome-do-arquivo.R`, onde $n$ varia de 00 até 17.
  
Mas, como extrair esses nomes?

Para responder essa pergunta, vamos usar um pacote chamado `fs` (*file system*).
Ele possui uma função denominada **path_file()**, que faz justamente o que 
precisamos.
Podemos, então, salvar numa variável **nomes_links_uesc** tais nomes:

```{r, eval=FALSE}
nomes_links_uesc <- fs::path_file(links_uesc)
```

Vimos que a função `download.file()` precisa de dois argumentos para fazer o 
*download* de um arquivo de texto plano: o *link* e o caminho para salvar o arquivo.
Já temos o *link* e, para não fazermos manualmente a criação de diretórios para
salvar os arquivos, vamos usar uma outra função do pacote `fs`: **dir_create()**.
Nela vamos escrever o caminho onde queremos salvar os arquivos, juntamente com
a lista dos nomes.

Como, nesse minicurso, faremos download de vários arquivos, vamos criar um
diretório mais geral, denominado **downloads/**, onde serão salvos os 
arquivos dos sites específicos estudados.

Por exemplo, para os arquivos desse site da UESC, criaremos um subdiretório por 
nome "arquivos_uesc/".
Vamos atribuir à variável **arquivos_uesc** todo esse procedimento (note que
o nome da variável é o mesmo nome da pasta onde salvaremos os arquivos desse site). 
O código fica assim:

```{r, eval=FALSE}
arquivos_uesc <- fs::dir_create("downloads/arquivos_uesc")
```

Por fim, vamos iterar o download para todos os 18 arquivos, fazendo:

```{r, eval=FALSE}
download.file(links_uesc, arquivos_uesc/nomes_links_uesc)
```

Maravilha, não?

Você pode conferir o *script* completo abaixo:

<details>
  <summary>
    Script para download dos arquivos, em R, disponíveis no site da UESC
  </summary>
  
```{r, eval=FALSE}
#==============================================================================
# Download de arquivos com extensão .R
# Ícaro Vidal Freire
# 2022-03-04
#==============================================================================

# carregando pacotes ------------------------------------------------------
library(magrittr)

# preparando url ----------------------------------------------------------
url_uesc <- "https://lec.pro.br/avale-es/r"

# preparando o site -------------------------------------------------------
site_uesc <- rvest::read_html(url_uesc)

# raspando os links -------------------------------------------------------
links_uesc <- site_uesc |>
  rvest::html_elements("li:nth-child(2) h5+ ul a") |>
  rvest::html_attr("href") %>%
  stringr::str_c("https://lec.pro.br", .)

# raspando os nomes dos arquivos ------------------------------------------
nomes_uesc <- fs::path_file(links_uesc)

# preparando pasta para download ------------------------------------------
arquivos_uesc <- fs::dir_create("downloads/arquivos_uesc")

# fazendo o download ------------------------------------------------------
download.file(links_uesc, arquivos_uesc/nomes_uesc)

#==============================================================================

```
  
</details>

### 5.2.2 Arquivos binários

Nessa seção, vamos fazer o download de arquivos binários no formato `pdf`.
O site onde se encontram esses arquivos é o da *Olimpíada Brasileira de Matemética* 
(OBM), especificamente na área da Revista Eureka:

<p align='center'>
  <a href='https://www.obm.org.br/revista-eureka/'> 
    https://www.obm.org.br/revista-eureka/
  </a>
</p>

Nosso objetivo é fazer o download das 42 revistas, no formato `pdf`, e organizar
esses arquivos com nomes seguindo determinado padrão.

O primeiro passo é fazer a leitura do site.
Antes, porém, vamos atribir à variável `url_eureka` o link do site:

```{r}
url_eureka <- "https://www.obm.org.br/revista-eureka/"
```

Prosseguimos, então, com a leitura, atribuindo à variável `site_eureka` seu 
resultado:

```{r}
site_eureka <- rvest::read_html(url_eureka)
```

Feito isso, precisamos dos elementos que contém os links que desejamos para 
download.
A seleção do CSS ajuda-nos a delimitar as opções adequadamente.

Entretanto, nesse ponto, perceba uma sutil diferença ao clicar sobre a imagem
de algum arquivo do pdf e num pequeno espaço, ao seu lado.
Para ser mais claro, vamos considerar o link associado à Revista nº 42:

```{r, echo=FALSE}
knitr::include_graphics("img/div_a-img.png")
```

Obviamente, o link que será extraído não se encontra na *tag* de "img".
Portanto, devemos clicar num pequeno espaço ao lado dessa imagem de pdf e depois
fazermos os ajustes, clicando novamente nos itens que não nos interessa no momento,
como por exemplo, nos links do cabeçalho da página.

Com o passo acima, um elemento CSS possível seria: "#revistas-list a".
Logo, podemos extrair os links assim:

```{r, eval=FALSE}
site_eureka |> 
  rvest::html_elements("#revistas-list a") |> 
  rvest::html_attr("href")
```


```{r, echo=FALSE}
site_eureka |> 
  rvest::html_elements("#revistas-list a") |> 
  rvest::html_attr("href") |> 
  utils::head(10)
```

Mas, para selecionarmos apenas o formato pdf, usamos: `stringr::str_subset(".pdf")`.
Vamos atribuir à variável `links_eureka` esses procedimentos:

```{r}
links_eureka <- site_eureka |> 
  rvest::html_elements("#revistas-list a") |> 
  rvest::html_attr("href") |> 
  stringr::str_subset(".pdf")
```

Se visualizarmos os nomes desses links, notaremos que não há um padrão único.
Para contornar isso, vamos criar uma lista com 42 nomes com o seguinte padrão:

- `n_eureka`; onde $n$ é um número que varia de 1 a 42.

Uma maneira de criar essa sequência de números é usarmos a função `seq()`, do
R Base:

```{r}
seq(1, 42)
```

Mas, vamos estabelecer que nosso padrão contenha sempre dois dígitos.
Então, para os algarísmos de 1 até 9, colocaremos o número 0 (zero) à esquerda 
deles.
Dessa forma, basta aglutinarmos o caractere "0" à sequência `seq(1, 9)`. 
A função `str_c()`, do pacote **stringr**, é adequada para isso:

```{r}
stringr::str_c("0", seq(1, 9))
```

Todavia, vamos concatenar esse resultado com os números restantes (de 10 a 42),
atribuindo à variável `index` (pois é uma indexação) esse procedimento:

```{r}
index <- c(stringr::str_c("0", seq(1, 9)), seq(10, 42))
```

Portanto, para criarmos a lista com 42 nomes padronizados, vamos aglutinar à
indexação o padão "_eureka", atribuindo à variável `nomes_eureka` esses 
procedimentos:

```{r}
nomes_eureka <- stringr::str_c(index, "_eureka.pdf")

nomes_eureka
```

Como já vimos, para criar um subdiretório, por nome "arquivos_eureka", no diretório `downloads`, usamos a função `dir_create`, do pacote **fs**.
Atribuindo esse passo à variável `arquivos_eureka`, temos:

```{r, eval=FALSE}
arquivos_eureka <- fs::dir_create("downloads/arquivos_eureka")
```

Por fim, podemos iterar esse procedimento para todos os arquivos com:

```{r, eval=FALSE}
download.file(links_eureka, arquivos_eureka/nomes_eureka)
```

> Se você for usuário Windows, deve acrescentar o argumento `mode = wb`: `download.file(links_eureka, arquivos_eureka/nomes_eureka), mode = wb`

Você pode conferir o *script* completo abaixo:

<details>
  <summary>
    Script para download de arquivos, em pdf, da Revista Eureka
  </summary>
  
```{r,eval=FALSE}
#==============================================================================
# Download das revistas Eureka
# Ícaro Vidal Freire
# 2022-03-04
#==============================================================================

# url do site -------------------------------------------------------------
url_eureka <- "https://www.obm.org.br/revista-eureka/"

# preparação do site ------------------------------------------------------
site_eureka <- rvest::read_html(url_eureka)

# raspagem dos dados ------------------------------------------------------
## extraindo links
links_eureka <- site_eureka |> 
  rvest::html_elements("#revistas-list a") |> 
  rvest::html_attr("href") |> 
  stringr::str_subset(".pdf")

## modificando os nomes
index <- c(stringr::str_c("0", seq(1, 9)), seq(10, 42))
nomes_eureka <- stringr::str_c(index, "_eureka.pdf")

## criando os diretórios e caminhos
arquivos_eureka <- fs::dir_create("downloads/arquivos_eureka")

# fazendo os downloads ----------------------------------------------------
download.file(links_eureka, arquivos_eureka/nomes_eureka)

#==============================================================================
```
  
</details>


### 5.2.3 Raspando tabelas

A função do pacote **rvest** para raspar uma tabela é `html_table()`.

Para exemplificarmos seu uso, consideremos a seguinte página da Wikipédia sobre
a linguagem de programação R:

<p align='center'>
  <a href='https://pt.wikipedia.org/wiki/R_(linguagem_de_programa%C3%A7%C3%A3o)'>
    https://pt.wikipedia.org/wiki/R_(linguagem_de_programa%C3%A7%C3%A3o)
  </a>
</p>

Aparentemente, a única tabela existente na página é a da seção "Versão".

Diretamente, poderíamos fazer:

```{r}
# url do site -----------------------------------------------------------------
url_wiki <- "https://pt.wikipedia.org/wiki/R_(linguagem_de_programa%C3%A7%C3%A3o)"

# leitura do site -------------------------------------------------------------
site_wiki <- rvest::read_html(url_wiki)

# extração da tabela ----------------------------------------------------------
tabelas <- rvest::html_table(site_wiki)

# exibindo o conteúdo ---------------------------------------------------------
tabelas
```

Para nossa surpresa há 9 tabelas nessa página!
Quem a escreveu usou do formato da tabela para organização das informações, mas
em apenas uma colocou elementos característicos de um quadro.

Veja que a classe do objeto "tabelas" é uma lista:

```{r}
class(tabelas)
```

Ainda analisando essa lista, percebemos que a tabela que desejamos encontra-se 
na 5º posição.
Portanto, podemos selecioná-la da seguinte maneira:

```{r}
tabela_wiki <- tabelas[[5]]

tabela_wiki
```

Poderíamos simplificar os passos da seguinte forma:

```{r, eval=FALSE}
# carregando pacote -----------------------------------------------------------
library(magrittr)

# url do site -----------------------------------------------------------------
url_wki <- "https://pt.wikipedia.org/wiki/R_(linguagem_de_programa%C3%A7%C3%A3o)"

# lendo e raspando os dados ---------------------------------------------------
tabela_wiki <- url_wki |> 
  rvest::read_html() |> 
  rvest::html_table() %>%
  .[[5]]

# exibindo a tabela -----------------------------------------------------------
tabela_wiki
```

Ainda podemos usar o elemento CCS para extrair a mesma tabela!
Quantas possibilidades, não?
Se você usar adequadamente o SelectorGadget, encontrará ".wikitable".
Você pode conferir como fica, no script abaixo.

<details>
  <summary>
    Script para download de arquivos, em pdf, da Revista Eureka
  </summary>
  
```{r,eval=FALSE}
#==============================================================================
# Raspando uma tabela da Wikipédia
# Ícaro Vidal Freire
# 2022-03-04
#==============================================================================

# carregando pacote -------------------------------------------------------
library(magrittr)

# preparando url ----------------------------------------------------------
url_wiki <- "https://pt.wikipedia.org/wiki/R_(linguagem_de_programa%C3%A7%C3%A3o)"

# preparando site ---------------------------------------------------------
site_wiki <- rvest::read_html(url_wiki)

# raspando a tabela -------------------------------------------------------
tabela_wiki <- site_wiki |>
  rvest::html_elements(".wikitable") |>
  rvest::html_table()

# exibindo a tabela -------------------------------------------------------

tabela_wiki

#==============================================================================

```
  
</details>

## 5.3 Construindo uma tabela para tomada de decisão

No site da livraria da USP, na seção "ASSUNTOS", ao escolhermos "Matemática", 
somos direcionados para essa página:

<p align='center'>
  <a href='https://www.edusp.com.br/loja/assuntos/21/matematica'>
    https://www.edusp.com.br/loja/assuntos/21/matematica
  </a>
</p>

Há uma lista de 19 livros (acesso em 04/03/2022), mas suponha que nosso objetivo 
seja acompanhar a variação do preço de três deles:

- Números: Uma Introdução à Matemática;
- Um Poeta, um Matemático e um Físico;
- Programação Matemática para Otimização de Processos.

Ainda mais: se o desconto dado pelo site for igual ou superior a 20% do valor do
livro, gostaríamos que uma tabela fosse exibida com alguma informação direta, como
por exemplo, "compre"; e, caso contrário, "aguarde".

Portanto, precisamos extrair:

- Os nomes dos livros;
- Os preços que estão na categoria "De ...";
- Os preços que estão na categoria "Por ...";
- Uma lista espacífica que desejamos comparar (a nossa lista com os três livros);
- Alguma condição para devolver os termos "compre" ou "aguarde.

Vamos fazer isso passo a passo; mas, antes de começarmos, é importante organizarmos
as coisas:

```{r, eval=FALSE}
# url do site -----------------------------------------------------------------
url_usp <- "https://www.edusp.com.br/loja/assuntos/21/matematica"

# lendo o site ----------------------------------------------------------------
site_usp <- url_usp |> 
  rvest::read_html()
```

```{bash, eval=FALSE}
Error in open.connection(x, "rb") : 
  SSL certificate problem: unable to get local issuer certificate
```

Notem que houve um problema de Certificado de SSL.
Vimos que, para contornar isso, retiramos a verificação do certificado 
(`ssl_verifypeer = FALSE`) com a função `config()`, do pacote **httr**, dentro 
da função `GET()`, do mesmo pacote; sendo tudo isso ANTES do `read_html()`:

```{r}
# url do site -----------------------------------------------------------------
url_usp <- "https://www.edusp.com.br/loja/assuntos/21/matematica"

# lendo o site ----------------------------------------------------------------
site_usp <- url_usp |> 
  httr::GET(httr::config(ssl_verifypeer = FALSE)) |> 
  rvest::read_html()
```

### 5.3.1 Extraindo os nomes dos livros

Utilizando o SelectorGadget, clicamos sobre um dos títulos do livro e fazemos os
ajustes necessários (aparecerão elementos no rodapé da página do site que não são
convenientes).

```{r, echo=FALSE}
knitr::include_graphics("img/usp_titulos.png")
```

Com isso, um possível CSS é: "#dvProdutos p".

```{r}
site_usp |> 
  rvest::html_elements("#dvProdutos p")
```

Queremos extrair os nomes dos livros.
Logo, interessa-nos o texto entre a tag `<p>`; e, para isso, usamos a função 
`text2()`:

```{r}
site_usp |> 
  rvest::html_elements("#dvProdutos p") |> 
  rvest::html_text2()
```

E, para retirar os caracteres indesejados de espaçamento, usamos a função 
`str_trim()`, do pacote **stringr**:

```{r}
site_usp |> 
  rvest::html_elements("#dvProdutos p") |> 
  rvest::html_text2() |> 
  stringr::str_trim()
```

Vamos salvar tudoo isso na variável `titulos_usp`:

```{r}
titulos_usp <- site_usp |> 
  rvest::html_elements("#dvProdutos p") |> 
  rvest::html_text2() |> 
  stringr::str_trim()
```

### 5.3.2 Criando uma lista de desejos

Nesse momento, depois que extraímos os títulos dos livros, interessa-nos selecionar
aqueles desejados à compra.
Basta criarmos um vetor e nomeá-lo "`lista_desejos`":

```{r}
lista_desejos <- c(
  "Números: Uma Introdução à Matemática",
  "Poeta, um Matemático e um Físico, Um:...",
  "Programação Matemática para Otimização..."
)
```

> Os nomes devem ser EXATAMENTE como aparecem na raspagem dos títulos.

### 5.3.3 Extraindo os preços 

Para extração dos preços, lembremos que são duas categorias: 

- "De ..."; que substituiremos por `preco_antigo_usp`.
- "Por ..."; que substituiremos por `preco_desconto_usp`.

#### 5.3.3.1 Preço antigo

Utilizando o SelectorGadget, ao clicarmos na região onde há um "traço" no preço,
encontramos o seguinte elemento CSS: "strike".

```{r}
site_usp |> 
  rvest::html_elements("strike")
```

```{r, echo=FALSE}
knitr::include_graphics("img/usp_preco-antigo.png")
```

Retirando o texto dessa *tag*, temos:

```{r}
site_usp |> 
  rvest::html_elements("strike") |> 
  rvest::html_text2()
```

Obviamente, queremos apenas os valores numéricos, visto que ainda vamos operar
com os mesmos para criarmos condições para tomada de decisão.
Assim, observando o padrão, interessa-nos os elementos depois do 3ª caractere, 
ou seja, a partir do 4º caractere.
A função `str_sub()`, do pacote **stringr** faz isso perfeitamente:

```{r}
site_usp |> 
  rvest::html_elements("strike") |> 
  rvest::html_text2() |> 
  stringr::str_sub(4)
```

Agora, sabemos que o R identifica o ponto como separador decimal.
Logo, devemos substituir a "vírgula" pelo "ponto".
Para isso, usamo a função `str_replace_all()`:

```{r}
site_usp |> 
  rvest::html_elements("strike") |> 
  rvest::html_text2() |> 
  stringr::str_sub(4) |> 
  stringr::str_replace_all(",", ".")
```

Mas, ainda temos um conjundo de "caracteres" (*character*) e não números 
(*numeric*).
Para extrairmos apenas os números, podemos usar a função `parse_double()`, do 
pacote **readr**:

```{r}
site_usp |> 
  rvest::html_elements("strike") |> 
  rvest::html_text2() |> 
  stringr::str_sub(4) |> 
  stringr::str_replace_all(",", ".") |> 
  readr::parse_double()
```

Vamos atribuir à variável `preco_antigo_usp` esses códigos:

```{r}
preco_antigo_usp <- site_usp |> 
  rvest::html_elements("strike") |> 
  rvest::html_text2() |> 
  stringr::str_sub(4) |> 
  stringr::str_replace_all(",", ".") |> 
  readr::parse_double()
```

#### 5.3.3.2 Preço com Desconto

```{r, echo=FALSE}
knitr::include_graphics("img/usp_preco-desconto.png")
```

Procedendo de forma análoga, podemos extrair o `preco_desconto_usp`:

```{r}
preco_desconto_usp <- site_usp |> 
  rvest::html_elements("h2+ h2") |>     # elemento CSS
  rvest::html_text2() |>                # extração do conteúdo (texto)
  stringr::str_trim() |>                # eliminando espaços indesejáveis
  stringr::str_sub(8) |>                # extraindo a partir do 8º caractere
  stringr::str_replace(",", ".") |>     # substituindo 'virgula' por 'ponto'
  readr::parse_double()                 # transformando 'character' para 'numeric'
```

### 5.3.3 Construindo a tabela

#### 5.3.3.1 Um script como estamos acostumados

Para construirmos uma tabela, usaremos a função `tibble()` do pacote de mesmo nome.
Nessa tabela, existirão quatro colunas (variáveis): _titulo_, _preco_antigo_, _preco_desconto_, _decisao_.

Na variável `decisão`, precisamos colocar uma **condicional**. 
Usaremos, então, a função **`if_else()`** do pacote `dplyr`.
Nossa condição é: se `preco_desconto` for _menor ou igual_ a 20% de desconto no `preco_antigo`, então desejamos que apareceça a mensagem "compre!!!"; caso contrário, que apareça a mensagem "aguarde".
Um desconto de, pelo menos, 20% é multiplicarmos o `preco_antigo` por `(1 - 0.2)`; assim,
usando os operadores lógicos, podemos escrever a condição dessa forma:

<p align='center'>
  `preco_desconto <= (1 - 0.2) * preco_antigo`
</p>

Portando, os argumentos da função `if_else` ficará assim:

```{r, eval=FALSE}
dplyr::if_else(preco_desconto <= (1 - 0.2) * preco_antigo), "compre!!!", "aguarde")
```

Agora, podemos construir a tabela:

```{r}
tibble::tibble(
  titulo       = titulos_usp,
  preco_antigo = preco_antigo_usp,
  preco_novo   = preco_desconto_usp,
  decisao      = dplyr::if_else(preco_novo <= (1 - 0.2) * preco_antigo, "compre!!!", "agarde")
)
```

Obviamente, queremos filtrar, apenas, os livros de nossa lista de desejos.
Usaremos um operador do R Base que nos dá a ideia de "inclusão".
De fato, queremos apenas _filtrar_ da variável `titulo`, queles que estão na `lista_desejos`.
O operador em questão é `%in%`.

Voltando à tabela, que denominaremos `tabela_usp`, temos o código:

```{r}
# criando a tabela com o filtro -----------------------------------------------
tabela_usp <- 
  tibble::tibble(
    titulo       = titulos_usp,
    preco_antigo = preco_antigo_usp,
    preco_novo   = preco_desconto_usp,
    decisao      = dplyr::if_else(preco_novo <= (1 - 0.2) * preco_antigo, "compre!!!", "agarde")
  ) |> 
  dplyr::filter(titulo %in% lista_desejos)

# exibindo a tabela -----------------------------------------------------------
tabela_usp
```

Você pode conferir o código completo, abaixo:

<details>
  <summary>
    Script para construção de tabela de decisão para compra de livros
  </summary>
  
```{r, eval=FALSE}
#==============================================================================
# Tabela para tomada de decisão na compra de livros da USP
# Ícaro Vidal Freire
# 2022-03-04
#==============================================================================

# preparando a url --------------------------------------------------------
url_usp <- "https://www.edusp.com.br/loja/assuntos/21/matematica"

# preparando o site -------------------------------------------------------
site_usp <- url_usp |>
  httr::GET(httr::config(ssl_verifypeer = FALSE)) |>
  rvest::read_html()

# raspando todos os títulos -----------------------------------------------
titulos_usp <- site_usp |>
  rvest::html_elements("#dvProdutos p") |>
  rvest::html_text2() |>
  stringr::str_trim()

# construindo uma lista de desejos ----------------------------------------
lista_desejos <- c(
  "Números: Uma Introdução à Matemática",
  "Poeta, um Matemático e um Físico, Um:...",
  "Programação Matemática para Otimização..."
)

# raspando o preço antigo -------------------------------------------------
preco_antigo_usp <- site_usp |>
  rvest::html_elements("strike") |>
  rvest::html_text2() |>
  stringr::str_sub(4) |>
  stringr::str_replace_all(",", ".") |>
  readr::parse_double()

# raspando o novo preço ---------------------------------------------------
preco_novo_usp <- site_usp |>
  rvest::html_elements("h2+ h2") |>
  rvest::html_text2() |>
  stringr::str_trim() |>
  stringr::str_sub(8) |>
  stringr::str_replace_all(",", ".") |>
  readr::parse_double()

# criando tabela de decisão -----------------------------------------------
tabela_usp <-
  tibble::tibble(
    titulo       = titulos_usp,
    preco_antigo = preco_antigo_usp,
    preco_novo   = preco_novo_usp,
    decisao      = dplyr::if_else(preco_novo <= (1 - 0.2) * preco_antigo, "compre!!!", "agarde")
  ) |>
  dplyr::filter(titulo %in% lista_desejos)

#==============================================================================
```
  
<details>

#### 5.3.3.2 Um script mais geral

Vamos melhorar um pouco o script da subseção anterior: como modificar o script
para que o mesmo possua uma variável mais flexível na porcentagem de desconto?

Esclarecendo mais: no script passado, estabelecemos, pelo menos, 20% como 
desconto desejado. 
Mas,se quiséssemos, agora, pelo menos, 10%?
E se amanhã, quiséssemos pelo menos 12%?

Ficar olhando todo o código e mudando a porcentagem pode não ser uma boa opção.
Se, ao menos, pudéssemos separar o corpo do código com o ato que desejamos, já
seria uma boa opção.
Uma forma de fazer isso é criar uma função, que denominaremos `desconto_usp()`, 
que incorpora o código acima, ou seja, que raspe os dados e retorne uma tabela 
de decisão, mas que mantenha a porcentagem como uma variável.
Assim, se quisséssemos conferir para 20%, bastaria modificar o argumento da função
assim: `desconto_usp(0.2)`.

Então, vamos usar a estrutura `function(variavel){códigos}` para isso.
No lugar de "variável", vamos denotar por "percent", para lembrarmos que trata-se
da porcentagem.
Depois, no lugar onde está `(1 - 0.2)`, mudamos para `(1 - percent)`; ou seja, 
estamos retirando um valor numérico específico e colocando uma variável no lugar 
dele.
Por fim, ao final de todo o código, depois de termos definido a função, escrevemos
`desconto(0.2)`.

Veja o script completo abaixo:

<details>
  <summary>
    Script para criação de uma função para tabela de decisão
  </summary>
  
```{r, eval=FALSE}
#==============================================================================
# Tabela para tomada de decisão na compra de livros da USP (MODO FUNÇÃO)
# Ícaro Vidal Freire
# 2022-03-04
#==============================================================================

# criando a função ============================================================

desconto_usp <- function(percent){
  # preparando a url --------------------------------------------------------
  url_usp <- "https://www.edusp.com.br/loja/assuntos/21/matematica"
  
  # preparando o site -------------------------------------------------------
  site_usp <- url_usp |>
    httr::GET(httr::config(ssl_verifypeer = FALSE)) |>
    rvest::read_html()
  
  # raspando todos os títulos -----------------------------------------------
  titulos_usp <- site_usp |>
    rvest::html_elements("#dvProdutos p") |>
    rvest::html_text2() |>
    stringr::str_trim()
  
  # construindo uma lista de desejos ----------------------------------------
  lista_desejos <- c(
    "Números: Uma Introdução à Matemática",
    "Poeta, um Matemático e um Físico, Um:...",
    "Programação Matemática para Otimização..."
  )
  
  # raspando o preço antigo -------------------------------------------------
  preco_antigo_usp <- site_usp |>
    rvest::html_elements("strike") |>
    rvest::html_text2() |>
    stringr::str_sub(4) |>
    stringr::str_replace_all(",", ".") |>
    readr::parse_double()
  
  # raspando o novo preço ---------------------------------------------------
  preco_novo_usp <- site_usp |>
    rvest::html_elements("h2+ h2") |>
    rvest::html_text2() |>
    stringr::str_trim() |>
    stringr::str_sub(8) |>
    stringr::str_replace_all(",", ".") |>
    readr::parse_double()
  
  # criando tabela de decisão -----------------------------------------------
  tabela_usp <-
    tibble::tibble(
      titulo       = titulos_usp,
      preco_antigo = preco_antigo_usp,
      preco_novo   = preco_novo_usp,
      decisao      = dplyr::if_else(preco_novo <= (1 - percent) * preco_antigo, "compre!!!", "agarde")
    ) |>
    dplyr::filter(titulo %in% lista_desejos)
  # exibindo a tabela ---------------------------------------------------------
  tabela_usp
}

# usando a função =============================================================
desconto_usp(0.2)
#==============================================================================
```

</details>

Pronto, agora, caso você queira modificar a porcentagem, basta ir até o argumento
final da função e mudar o número.

Então, você pode salvar o arquivo (vamos usar o nome `usp.R`) na sua área de 
trabalho principal e, usando o terminal, digitar:

```{r, eval=FALSE}
Rscript usp.R
```

Pronto! 
Você receberá, depois de alguns segundos, a tabela de decisão.

#### 5.3.3.3 Um script com interação no terminal (um programa)

A solução anterior é muito útil, mas ainda ficamos com a sensação de que poderia
melhorar ...
Por exemplo, seria possível criarmos um programa que perguntásse-nos a porcentagem
do desconto e, depois de digitado o valor, ele retornasse a tabela de decisão?
Sim! Isso é possível!
Basta acrescentarmos, depois da função construída, os comandos (notem o ";", ao 
final dos comandos):

```{r, eval=FALSE}
cat("Digite uma porcentagem para o desconto: "); # exibe uma mensagem na tela e aguarda um valor
percent <- readLines("stdin", n = 1);            # armazena valor que digitarmos
desconto_usp(percent)                            # calcula o valor na função e retorna a tabela
```

É interessante definirmos a variável `percent` como sendo numérica.
Para isso, usamos a conhecida função `parse_double()`, do pacote `readr`.

O cógido completo pode ser visto abaixo:

<details>
  <summary>
    Script para Tabela de Decisão (Modo Interativo)
  </summary>
  
```{r, eval=FALSE}
#==============================================================================
# Criando tabela de decisão para compra de livros (Modo Interativo)
# Ícaro Vidal Freire
# 2022-03-04
#==============================================================================

# criando a função ------------------------------------------------------------
desconto_usp <- function(percent){
  # passando a variável para numérica
    percent <- readr::parse_double(percent)
  # preparando a url
    url_usp <- "https://www.edusp.com.br/loja/assuntos/21/matematica"
  # preparando o site 
    site_usp <- url_usp |>
      httr::GET(httr::config(ssl_verifypeer = FALSE)) |> 
      rvest::read_html()
  # raspando titulos
    titulos_usp <- site_usp |> 
      rvest::html_elements("#dvProdutos p") |> 
      rvest::html_text2() |> 
      stringr::str_trim()
  # raspando preço antigo
    preco_antigo_usp <- site_usp |> 
      rvest::html_elements("strike") |> 
      rvest::html_text2() |> 
      stringr::str_sub(4) |> 
      stringr::str_replace_all(",", ".") |> 
      readr::parse_double()
  # raspando preço com desconto
    preco_novo_usp <- site_usp |> 
      rvest::html_elements("h2+ h2") |> 
      rvest::html_text2() |>
      stringr::str_trim() |> 
      stringr::str_sub(8) |> 
      stringr::str_replace_all(",", ".") |> 
      readr::parse_double()
  # criando tabela de decisão geral
    tabela_geral <- tibble::tibble(
      titulo = titulos_usp,
      preco_antigo = preco_antigo_usp,
      preco_novo = preco_novo_usp,
      desconto = dplyr::if_else(preco_novo <= (1 - percent) * preco_antigo, "compre!!!", "aguarde")
    ) 
  # criando lista de desejos
    lista_desejos <- c(
      "Introdução à Mecânica Clássica", 
      "Poeta, um Matemático e um Físico, Um:...", 
      "Programação Matemática para Otimização..."
    )
  # filtrando as opções desejadas
    tabela_usp <- tabela_geral |> 
      dplyr::filter(titulo %in% lista_desejos)
  # exibindo tabela de decisão
    print(tabela_usp)
}

# modo interativo no terminal -------------------------------------------------
cat("Digite uma porcentagem: ");
percent <- readLines("stdin", n = 1);
desconto_usp(percent)
```

</details>

## 5.4 Raspagem com várias páginas

Vamos usar o site [Mises Brasil](https://mises.org.br/), que percente ao 
**Instituto Ludwig von Mises - Brasil** ("IMB").

> "O IBM é uma associação voltada à produção e à disseminação de estudos 
econômicos e de ciências sociais que promovam os princípios de livre mercado e 
de uma sociedade livre."

Ao entrarmos na parte de "Artigos", subseção "arquivo"; encontraremos uma
lista de todos os artigos disponibilizados pelo site.
São 25 páginas que pretendemos raspar os `títulos`, os `autores` e as `datas`.

A url considerada (clicando na página 1) é:

```{r}
url_mises <- "https://www.mises.org.br/Articles_Thumbs.aspx?page=0&type=0&text="
```

Quando extraimos dados de várias páginas, as requisições no servidor almentam
consideravelmente.
Respeitar a regra estabelecida por cada site é fundamental.

O pacote [`polite`](https://dmi3kno.github.io/polite/) fornece-nos duas funções
estremamente úteis nesse processo "polido" (_polite_) de fazer requisições ao
servidor.

A primeira função é a [`bow(url, user_agent = ...)`](https://dmi3kno.github.io/polite/reference/bow.html).
Ela, basicamente, apresenta suas requisições às regras do site pretendido e as
respeita.
Inclusive você pode adicionar seu nome ou projeto no argumento `user_agent`, mas
não é obrigatório.

```{r}
polite::bow(url_mises, user_agent = "Curso de Extensão: Raspando os Dados da Web com o R")
```

Notem que o site é "raspável" e possui um _delay_ de 5 segundos.
Ou seja, a cada requisição, ele espera 5 segundos.
Isso mostra que não será tão imetiato esse processo de raspagem, visto que terá 
um tempo de espera a ser considerado.

Depois de fazer as requisições ao site, devemos extrair o `html` da página.
Vinhamos fazendo isso com `rvest::read_html()`, mas o pacote `polite` fornece
a [`scrape()`](https://dmi3kno.github.io/polite/reference/scrape.html) que faz
a mesma coisa e ainda possui diversos parâmetros.

Vamos atribuir à variável `site_mises` o processo de pedir requisição, com `bow()`; e,
ler o `html`, com `scrape()`.
Podemos usar o `pipe` para concatenar tudo:

```{r}
site_mises <- url_mises |> 
  polite::bow() |> 
  polite::scrape()
```

São 25 páginas, mas é importante fazermos a raspagem de uma das páginas (no caso,
a primrira) para visualizarmos algum padrão e, assim, formarmos a ideia de 
generalização às outras.

### 5.4.1 Raspagem na primeira página

Usando corretamente o SelectorGadget, podemos extrair os elementos CSS associados, 
respectivamente à _data_, _autor_ e _título_, bem como usar as ferramentas de 
limpeza para separá-los.
O código abaixo resume essas ideias:

```{r}
# raspando a data -------------------------------------------------------------
data_mises_pg1 <- site_mises |> 
  rvest::html_elements(".mis-text-sans span:nth-child(1)") |> 
  rvest::html_text2() |> 
  lubridate::dmy()

# raspando o autor ------------------------------------------------------------
autor_mises_pg1 <- site_mises |> 
  rvest::html_elements(".mis-text") |> 
  rvest::html_text2()

# raspando o título -----------------------------------------------------------
titulo_mises_pg1 <- site_mises |> 
  rvest::html_elements(".thumbsArticle") |> 
  rvest::html_text2()
  
```

Na raspagem das datas, usamos a função `dmy()`, do pacote `lubridate` (que é um 
dos pacotes do `tidyverse`).
O seu uso foi necessário, pois, quando extraímos as datas, na realidade extraímos 
um conjunto de caracteres.
A função `dmy()` diz ao R que esse conjunto de caracteres, são datas!


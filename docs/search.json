{
  "articles": [
    {
      "path": "00_pre-requisitos.html",
      "title": "Pré-requisitos",
      "description": "O que preciso para fazer esse minicurso?\n",
      "author": [],
      "contents": "\nMundo Ideal\nObviamente, se você quiser instalar o R (linguagem e ambiente de programação que usaremos) e o RStudio (interface gráfica que deixa nossa vida mais fácil ao trabalhar com o R) em seu computador, será ótimo para estudos a longo prazo, bem como aprofundamento na linguagem! Para isso, veja esse tutorial: R-Guia de Instalação\nMundo Real\nPorém, para nosso minicurso, você só precisa criar uma conta no RStudio Cloud. Não será preciso instalar o R, nem o RStudio em seu computador! Será tudo pela nuvem!\nUma internet estável também é desejável.\nPasso a passo\nSeguindo as passos a seguir, você estará apto para criar uma conta no RStudio Cloud.\n\n1º Passo\nAcesse o site https://rstudio.cloud/\nClique em Sign Up (1.)\n\n\n\n2º Passo\nÉ suficiente escolher a opção Free (2.)\nDepois aperte em Sign Up (3.)\n\n\n\n3º Passo\nOu preencha seus dados e crie uma conta;\nOu use uma conta do Google (ou GitHub) para autenticação.\n\n\n\n\nConhecendo o RStudio\nO que mais usaremos?\nPara quem usa Chrome, basta instalar a extensão, disponível no link:\nExtensão Chrome\nPara quem usa Mozilla ou algum outro browser não derivado do Chrome, pode usar essa função:\n\n\n\nSiga os seguintes passos para usar a função acima:\nCopie o código acima;\nCole o código em seu navegador de internet (browser);\nSalve como “Favorito” na barra de navegação do browser.\nPronto! Veremos mais sobre essa ferramenta quando falarmos sobre html.\n\n\n\n",
      "last_modified": "2021-12-22T18:40:17-03:00"
    },
    {
      "path": "01_web-scraping_panorama.html",
      "title": "O que é Web Scraping?",
      "description": "Um panorama de nosso Minicurso\n",
      "author": [],
      "contents": "\nAntes de começar … um aviso!\nObviamente, o processo de “raspagem de dados” na internet envolve muito mais do que tangenciaremos nesse Minicurso!\nNosso objetivo é que você tenha um primeiro contato com esse “mundo” e que seja um contato prazeroso, claro!\nEntendemos que o R, especificamente com o pacote do tidyverse denominado rvest pode dar essa relação amigável entre a linguagem do html, própria da internet, e as etapas racionalmente encadeadas para extrair o que desejamos delas.\nVamos, então, entender mais sobre o que é o processo de Web Scraping.\n1. O que é o Web Scraping?\nO termo scraping vem do verbo, em inglês, scrape, que significa “raspar”. Já o termo web, pode significar “rede”, no caso, “rede de internet” 1. Então, poderíamos dizer que “Web Scraping” é um processo de “Raspagem da Rede”.\nFicou estranho, né? Talvez porque … não é só isso!\nNa internet, muita informação (dados) pode está espalhada de forma não muito estruturada para análise ou tomada de decisões.\n\nO processo de leitura, seleção, limpeza e armazenagem desses dados de forma automatizada é o que queremos dizer por “Web Scraping”.\n\nPor isso, vamos falar em “Raspagem de dados” como sinônmimo de “Web Scraping” ao longo desse texto.\n1.1 Entendendo as etapas\nObviamente, existem muitas formas de explicar o processo de web scraping. Todavia, ficaremos numa explicação intuitiva e mais direta, que resumimos em três etapas:\n\n1º etapa: Leitura\nPrimeiro, você deve saber que a página de um site é fruto de uma compilação/construção. Existe uma linguagem de marcação que estabelece parâmetros para configurações do texto.\nEm outras palavras (os antigos entenderão) existe uma Matrix por trás de cada página de um site. Ficaremos, apenas, na sua escrita.\nVamos testar: aperte o seguinte conjunto de teclas em seu computador:\n\nCTRL + u\n\nO que você viu (caso tenha apertado as teclas citadas acima) é, na realidade, como essa página foi escrita! A linguagem de marcação utiliazada é o html (abreviação para HyperText Markup Language).\nEntão, para que você saiba “raspar” algum dado de um site da internet, deve-se “ler” o html associado à página do site. Falaremos um pouco sobre as características do html daqui a pouco, mas, por enquanto, apenas considere que a leitura da página que você deseja, deve ser no html associado à mesma. Vamos denominar essa etapa de leitura.\n\nO pacote rvest usa a função read_html() para isso, não se preocupe!\n\n2º etapa: Arrumação\nTudo bem, você fez a “leitura” do site, mas nem tudo está como você deseja, não? Existem apenas certos “elementos” que serão úteis para o que desejamos. Talvez uma lista, ou um parágrafo, ou links , ou tabelas, etc. Você deve selecionar esse agrupamento específico do html que foi realizado na “leitura”. Vamos chamar essa etapa de seleção\nTodavia, atrelada à etapa de “seleção”, existe uma subetapa: a de limpeza. Isso porque, existem muitos símbolos e caracteres do html que não desejamos na saída do processo.\nEm alguns casos, esse processo de “limpeza” é bem delicado e trabalhoso! Poderíamos até separar em uma etapa específica do Web Scraping, mas para uma introdução, vamos considerar como uma etapa só: Arrumação.\n\nO R disponibiliza muitas funções para a etapa de Seleção e Limpeza. Pacotes como o dplyr e stringr serão muito úteis nesse processo!\n\n3º etapa: Armazenagem\nPor fim, o processo de organizar os dados colhidos nas etapas anteriores, de maneira que possam ser acessados de forma direta, prática e “visual”, vamos chamar de Armazenagem.\nA saída pode ser um arquivo .csv, ou uma lista de download, ou simplesmente uma saída organizada em um terminal. Tudo dependerá de sua necessidade.\n\n1.1.1 Visualização das etapas do Web Scraping\nAs etapas podem ser “visualizadas” na figura abaixo:\n\n\n\nÉ natural sabermos, então, um mínimo da estruturação de um texto em html. Mas, isso veremos no próximo texto!\n\n\n\nNa realidade, “Web (que vem do”www” – World Wide Web) é um dos processos de acesso à internet.↩︎\n",
      "last_modified": "2021-12-22T19:01:12-03:00"
    },
    {
      "path": "index.html",
      "title": "Raspando os Dados da Web",
      "description": "Uma Indrodução ao R\n",
      "author": [
        {
          "name": "Ícaro Vidal Freire",
          "url": {}
        }
      ],
      "contents": "\nObjetivo do Minicurso\nAntes de falarmos formalmente sobre o objetivo do Minicurso, considereremos as seguintes situações:\n\n1º Situação\nEncontramos um site que disponibiliza, gratuitamente, vários materiais que julgamos importantes armazenar também em nosso computador — para o caso de usá-los quando não estiver com internet disponível, por exemplo.\nVamos supor que são 30 arquivos no formato pdf.\nO que faríamos?\nClicaríamos em cada um deles e faríamos download desses arquivos manualmente? Bom, essa é uma opção válida, mas seria muito mais produtivo e elegante, se pudéssemos fazer o download de forma automatizada, não? Todos os 30 arquivos, de “uma só vez”, salvos num diretório (pasta) específico de nosso computador! Seria uma maravilha, não?\n2º Situação\nSuponha, agora, que desejamos comprar alguns livros de um site que sempre oferece promoções interessantes. Mas, previamente estabelecemos que a compra seria realizada se esses livros estivessem com 30% de desconto.\nObviamente poderíamos entrar no site todos os dias; procurar um a um; e, calcularmos se o desconto aconteceu. Mas, e se criássemos um script (uma sequência, encadeada, de comandos para que um programa execute uma ação) que possui como resultado uma tabela com os preços diários exibidos, já com o desconto efetivado, para que pudéssemos tomar uma decisão rapidamente?\n\nFormalizando o objetivo\nEssas duas situações são comumente encontradas no trabalho do professor ou estudante.\nO objetivo desse minicurso é oferecer ferramentas para que, pelo menos, as duas situações, acima expostas, possam ser resolvidas de maneira racional, rápida e prazerosa.\nPara isso, introduziremos uma linguagem (e ambiente) de programação, denominada R. Na realidade, nosso foco será voltado a certos pacotes desenvolvidos que unificam uma estrutura de linguagem em R. Veremos que tal característica facilita muito o aprendizado das funções e potencialidades do R.\n\nNão é objetivo desse minicurso uma exaustiva análise ou exibição de funções, estruturas, ou objetos em R.\n\nApenas tangenciaremos alguns pacotes para usarmos as funções neles contidas, necessárias para solucionarmos as duas situações expostas no início desse texto. Logo, será uma Introdução ao R, mostrando que, dentre outras coisas, podemos fazer web scrape (“raspagem” de dados na internet) de maneira bem intuitiva e racional, ao mesmo tempo!\nPara isso, dividimos esse minicurso em três dias, para que a sedimentação das informações seja adequada e, assim, o minicurso seja usufruído da melhor maneira possível.\nEspero que gostem!\nEstruturação do Minicurso\n\n1º Dia\nApresentação dos objetivos, da plataforma RStudio Cloud e da metodologia;\nO que é Webscraping?\nTangenciando a estrutura de um arquivo html;\nUsando o SelectorGadget;\nINTERVALO (~ 15 min)\nVendo como funciona na prática!\nDownload simultâneo de vários arquivos de texto plano\n\n2º Dia\nIntrodução ao R\nO que é o R?\nObjetos e Funções Básicas no R\n\nINTERVALO (~ 15 min)\nAlgo sobre o Tidyverse\ntibble, dplyr;\nstringr;\nrvest\n\nDuas funções do pacote fs (File System)\n3º Dia\nDownload simultâneo de vários arquivos binários (pdf);\nDownload e limpeza de vários arquivos binários (pdf);\nMontando uma lista de preços para tomada de decisão;\nRaspagem de dados em mais de uma página.\n\n\n\n\n",
      "last_modified": "2021-12-22T18:38:23-03:00"
    }
  ],
  "collections": []
}

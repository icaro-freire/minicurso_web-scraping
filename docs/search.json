{
  "articles": [
    {
      "path": "00_pre-requisitos.html",
      "title": "Pré-requisitos",
      "description": "O que preciso para fazer esse minicurso?\n",
      "author": [],
      "contents": "\nMundo Ideal\nObviamente, se você quiser instalar o R (linguagem e ambiente de programação que usaremos) e o RStudio (interface gráfica que deixa nossa vida mais fácil ao trabalhar com o R) em seu computador, será ótimo para estudos a longo prazo, bem como aprofundamento na linguagem! Para isso, veja esse tutorial: R-Guia de Instalação\nMundo Real\nPorém, para nosso minicurso, você só precisa criar uma conta no RStudio Cloud. Não será preciso instalar o R, nem o RStudio em seu computador! Será tudo pela nuvem!\nUma internet estável também é desejável.\nPasso a passo\nSeguindo as passos a seguir, você estará apto para criar uma conta no RStudio Cloud.\n\n1º Passo\nAcesse o site https://rstudio.cloud/\nClique em Sign Up (1.)\n\n\n\n2º Passo\nÉ suficiente escolher a opção Free (2.)\nDepois aperte em Sign Up (3.)\n\n\n\n3º Passo\nOu preencha seus dados e crie uma conta;\nOu use uma conta do Google (ou GitHub) para autenticação.\n\n\n\n\nConhecendo o RStudio\nO que mais usaremos?\nPara quem usa Chrome, basta instalar a extensão, disponível no link:\nExtensão Chrome\nPara quem usa Mozilla ou algum outro browser não derivado do Chrome, pode usar essa função:\n\n\n\nSiga os seguintes passos para usar a função acima:\nCopie o código acima;\nCole o código em seu navegador de internet (browser);\nSalve como “Favorito” na barra de navegação do browser.\nPronto! Veremos mais sobre essa ferramenta quando falarmos sobre html.\n\n\n\n",
      "last_modified": "2021-12-23T10:03:23-03:00"
    },
    {
      "path": "01_web-scraping_panorama.html",
      "title": "O que é Web Scraping?",
      "description": "Um panorama de nosso Minicurso\n",
      "author": [],
      "contents": "\nAntes de começar … um aviso!\nObviamente, o processo de “raspagem de dados” na internet envolve muito mais do que tangenciaremos nesse Minicurso!\nNosso objetivo é que você tenha um primeiro contato com esse “mundo” e que seja um contato prazeroso, claro!\nEntendemos que o R, especificamente com o pacote do tidyverse denominado rvest pode dar essa relação amigável entre a linguagem do html, própria da internet, e as etapas racionalmente encadeadas para extrair o que desejamos delas.\nVamos, então, entender mais sobre o que é o processo de Web Scraping.\n1. O que é o Web Scraping?\nO termo scraping vem do verbo, em inglês, scrape, que significa “raspar”. Já o termo web, pode significar “rede”, no caso, “rede de internet” 1. Então, poderíamos dizer que “Web Scraping” é um processo de “Raspagem da Rede”.\nFicou estranho, né? Talvez porque … não é só isso!\nNa internet, muita informação (dados) pode está espalhada de forma não muito estruturada para análise ou tomada de decisões.\n\nO processo de leitura, seleção, limpeza e armazenagem desses dados de forma automatizada é o que queremos dizer por “Web Scraping”.\n\nPor isso, vamos falar em “Raspagem de dados” como sinônmimo de “Web Scraping” ao longo desse texto.\n1.1 Entendendo as etapas\nObviamente, existem muitas formas de explicar o processo de web scraping. Todavia, ficaremos numa explicação intuitiva e mais direta, que resumimos em três etapas:\n\n1º etapa: Leitura\nPrimeiro, você deve saber que a página de um site é fruto de uma compilação/construção. Existe uma linguagem de marcação que estabelece parâmetros para configurações do texto.\nEm outras palavras (os antigos entenderão) existe uma Matrix por trás de cada página de um site. Ficaremos, apenas, na sua escrita.\nVamos testar: aperte o seguinte conjunto de teclas em seu computador:\n\nCTRL + u\n\nO que você viu (caso tenha apertado as teclas citadas acima) é, na realidade, como essa página foi escrita! A linguagem de marcação utiliazada é o html (abreviação para HyperText Markup Language).\nEntão, para que você saiba “raspar” algum dado de um site da internet, deve-se “ler” o html associado à página do site. Falaremos um pouco sobre as características do html daqui a pouco, mas, por enquanto, apenas considere que a leitura da página que você deseja, deve ser no html associado à mesma. Vamos denominar essa etapa de leitura.\n\nO pacote rvest usa a função read_html() para isso, não se preocupe!\n\n2º etapa: Arrumação\nTudo bem, você fez a “leitura” do site, mas nem tudo está como você deseja, não? Existem apenas certos “elementos” que serão úteis para o que desejamos. Talvez uma lista, ou um parágrafo, ou links , ou tabelas, etc. Você deve selecionar esse agrupamento específico do html que foi realizado na “leitura”. Vamos chamar essa etapa de seleção\nTodavia, atrelada à etapa de “seleção”, existe uma subetapa: a de limpeza. Isso porque, existem muitos símbolos e caracteres do html que não desejamos na saída do processo.\nEm alguns casos, esse processo de “limpeza” é bem delicado e trabalhoso! Poderíamos até separar em uma etapa específica do Web Scraping, mas para uma introdução, vamos considerar como uma etapa só: Arrumação.\n\nO R disponibiliza muitas funções para a etapa de Seleção e Limpeza. Pacotes como o dplyr e stringr serão muito úteis nesse processo!\n\n3º etapa: Armazenagem\nPor fim, o processo de organizar os dados colhidos nas etapas anteriores, de maneira que possam ser acessados de forma direta, prática e “visual”, vamos chamar de Armazenagem.\nA saída pode ser um arquivo .csv, ou uma lista de download, ou simplesmente uma saída organizada em um terminal. Tudo dependerá de sua necessidade.\n\n1.1.1 Visualização das etapas do Web Scraping\nAs etapas podem ser “visualizadas” na figura abaixo:\n\n\n\nÉ natural sabermos, então, um mínimo da estruturação de um texto em html. Mas, isso veremos no próximo texto!\n\n\n\nNa realidade, “Web (que vem do”www” – World Wide Web) é um dos processos de acesso à internet.↩︎\n",
      "last_modified": "2021-12-23T10:03:23-03:00"
    },
    {
      "path": "02_intro-html.html",
      "title": "Entendendo o html",
      "description": "Na realidade tangenciando o html (e citando o CSS)\n",
      "author": [],
      "contents": "\n\nContents\n2. Estrutura do html\n3. CSS?\n3.1 Como funciona o SelectorGadget?\n3.1.1 Fazendo na prática\n\n\n\n2. Estrutura do html\nObserve o conjunto de códigos abaixo:\n\n\n\nO browser (seu navegador de internet favorito) interpreta esses comandos e produz uma saída amigável, com a qual estamos acostumamos!\nVeja como fica o código e sua saída, lado a lado:\n\n\n\nAlgumas coisas saltam aos olhos nesse código:\nNa linha 1 é exibida a classe que o texto foi escrito;\nDa linha 2 até a linha 5 está uma parte do texto (delimitda pelo elemento head). Essa parte não contém elementos que aparecem explicitamente na página gerada, mas é de extrema importância para configurações;\nDa linha 5 até a linha 22 está o corpo do texto (delimitado pelo elemento body). Encontra-se, nessa parte, o conteúdo principal do texto.\nOu seja, há uma certa estrutura no html que podemos resumir, graficamente, assim:\n\n\n\nInicialmnte, percebemos que, para delimitar elementos do html, usamos tags.\n\n<elemento> ... <\/elemento>\n\nAlgumas tags não precisam de “abertura e fechamento”, mas em sua maioria sim! Vejam que, para o fechamento, usamos uma barra “/”.\n“Elementos” no html são compostos por tags que especificam um “elemento”, seus “atributos” e o “conteúdo”. A estrutura visual é mais ou menos assim:\n\n\n\nVeja que, nos “elementos”, estão:\nelementos-pai, delimitados por tags;\npossíveis atributos, que possuem “nome” e “valor”;\npossíveis elementos-filhos;\ne o seu próprio conteúdo.\nPor exemplo, o código abaixo é um dos “elementos” que se encontram no código inicial desse texto.\n<a href='https://github.com/icaro-freire/site_webscraping'> \n  Repositório <b>GitHub<\/b> \n<\/a>\nNele, encontram-se:\no “elemento-pai” a e o “elemento-filho” (ou seja, que está contido no “a”) b;\num “atributo” do “elemento-pai”, a saber href=‘https://github.com/icaro-freire/site_webscraping’\ncujo nome é href\ncujo valor é https://github.com/icaro-freire/site_webscraping, geralmente delimitado por aspas (simples ou dupla).\n\nPor curiosidade, uma das características do elemento “a” (anchor, que significa “âncora”) é colocar hiperlinks em algum objeto (texto, figuras, etc.). Por isso, um atribulo de “a” é o “href” (h(ypertext) ref(erence), ou seja, “referência para hipertexto”). O conteúdo do elemento “a” é o texto “Repositório GitHub”, sendo que a palavra “GitHub” está em negrito (boldface, em inglês). Por isso, há um elemento-filho “b” que demarca o negrito.\nObviamente, não cobriremos nem a décima parte do total de “elementos” que compõem o html. Ficaremos com aqueles que serão usados nesse minicurso 1\n\nelemento\ndescricao\nh1, …, h6\nTamanhos crescentes dos títulos de seções\np\nDelimita parágrafos\n‘ol’ ou ‘ul’\nCria ‘listas ordenadas’ (ordered list) ou ‘listas não ordenadas’ (unordered list)\nli\nDemarca o início de um dos itens da lista\nimg\nInsere uma imagem no documento\na\nPara hiperlinks em páginas, imagens textos, etc.\nb\nPara negrito\ni\nPara itálico\ntable\nPara tabelas\n\nCom essas informações, já estamos minimamente familiarizados com o html para os objetivos desse curso, claro.\n3. CSS?\nCom tudo que aprendemos sobre html, podemos escrever um texto simples e direto, salvando em .html que nosso browser irá interpretar como uma página web.\nCaso queira fazer um teste, copie e cole o código abaixo num bloco de notas e salve em html por nome, por exemlo, index.html. Além disso, escolha uma figura e deixe-a na mesma pasta onde se encontra o arquivo html. Chame essa sua figura por minha-figura.png (aqui estou supondo que a extensão da figura seja png). Depois abra o arquivo index.html com seu navegador de internet padrão.\n\n<html>\n<head>\n  <title> Nome da Aba <\/title>\n<\/head>\n<body>\n  <h1 id='first'> Título Principal <\/h1>\n  <h2> Subtítulo <\/h2>\n  <p>Algum pequeno texto &amp; <b>ainda em negrito.<\/b><\/p>\n  <ul>\n    <li> Um item <\/li>\n    <li> \n      <a href=\"https://git.io/J6xEo\"> Repositório GitHub <\/a>\n    <\/li>\n    <li>\n      <a href=\"https://ufrb.edu.br/portal/\"> UFRB <\/a>\n    <\/li>\n  <\/ul>\n  <h3> Inserindo imagem centralizada<\/h3>\n  <p align='center'>\n    <img src='minha-figura.png' width='400'>\n  <\/p>\n<\/body>\n\nBom … convenhamos … fica feio, não?\nPorém, para modificarmos a posição dos objetos numa página web, bem como cores, espaçamentos, fontes, etc., precisamos do CSS (Cascading Style Sheets). Todavia, não abordaríamos o CSS num minicurso tão introdutório como esse!\nPara contornar isso, usaremos uma ferramenta que, justamente, retorna-nos o cógigo CSS de um elemento que estamos inspecionando. Isso torna a seleção inicial muito mais prática, embora não seja uma ferramenta muito precisa! Às vezes, será necessário selecionar algumas vezes o objeto até que fique do jeito desejamos. Usaremos o SelectorGadget.\n3.1 Como funciona o SelectorGadget?\nAo ativar a ferramenta, retângulos coloridos serão exibidos para que selecionemos o objeto desejado. Mas, geralmente, quando fazemos isso no primeiro “clique”, outras partes não desejadas também são selecionadas. Então, clicamos novamente sobre as partes que não desejamos!\n\nVeja: podem ocorrer duas etapas! Na primeira, selecionamos o que desejamos. Se algum elemento não desejado estiver também selecionado, clicamos nele em seguida.\n\nA cor “amarela” indica a seleção que desejamos e a cor “vermelha” indica a região que eliminamos com o segundo clique.\n3.1.1 Fazendo na prática\nConsidere o seguinte site:\n\nhttps://www.edusp.com.br/loja/assuntos/21/matematica\n\nNosso objetivo é selecionar a região onde se encontram os livros.\nAtivamos o SelectorGadget;\nMovimentamos o cursor do mouse até uma área que engloba o primeiro livro (ficará um retângulo de borda “vermelha” englobando a imagem, o título, os valores e o botão do carrinho de compras).\nClicamos nessa região. Em “verde” ficará a primeira região que clicamos e em amarelo TUDO o que desejamos selecionar. Num retângulo inferior de exibição do SelectorGadget aparecerá o elemento CSS: “.col-lg-3”.\nQuer dizer … nem tudo está correto! Englobamos coisas a mais! Basta rolar o cursor do mouse até o final da página e veremos que uma pequena região do “cartão de crédito” foi selecionada indevidamente! Então, basta clicarmos sobre ela até ficar “vermelha”. Com isso, o elemento CSS foi refinado para “#dvProdutos .col-lg-3”.\nVeja as imagens abaixo:\n\n\n\n\nPara mais, veja: https://developer.mozilla.org/pt-BR/docs/Web/HTML/Element↩︎\n",
      "last_modified": "2021-12-23T10:03:23-03:00"
    },
    {
      "path": "04_intro-tidyverse.html",
      "title": "O que usaremos do Tidyverse?",
      "description": "Explanação sucinta (apenas) das funções que usaremos do tidyverse & Cia.\n",
      "author": [],
      "contents": "\n\nContents\n4. Algo a mais sobre o Tidyverse\n4.1 O universo arrumado do tidyverse\n4.1.1 Uso dos pipes\n\n4.2 Pacotes que usaremos\n4.2.1 tibble\n4.2.2 readr\n4.2.3 dplyr\n4.2.4 rvest\n4.2.5 stringr\n4.2.6 purrr\n\n\n\n4. Algo a mais sobre o Tidyverse\n4.1 O universo arrumado do tidyverse\nVimos que o tidyverse é um pacote do R que agrega pacotes com uma certa “filosofia”, por exemplo, o modo de escrever as funções (geralmente com verbos em inglês que remotam à característica dessa função).\nSão muitos os pacotes que compõem o tidyverse (30 pacotes). Podemos listá-los com o seguinte comando:\n\n\ntidyverse::tidyverse_packages()\n\n\n [1] \"broom\"         \"cli\"           \"crayon\"        \"dbplyr\"       \n [5] \"dplyr\"         \"dtplyr\"        \"forcats\"       \"googledrive\"  \n [9] \"googlesheets4\" \"ggplot2\"       \"haven\"         \"hms\"          \n[13] \"httr\"          \"jsonlite\"      \"lubridate\"     \"magrittr\"     \n[17] \"modelr\"        \"pillar\"        \"purrr\"         \"readr\"        \n[21] \"readxl\"        \"reprex\"        \"rlang\"         \"rstudioapi\"   \n[25] \"rvest\"         \"stringr\"       \"tibble\"        \"tidyr\"        \n[29] \"xml2\"          \"tidyverse\"    \n\nEntretanto, usaremos, apenas, seis desses pacotes nesse minicurso:\nreadr; só usaremos a função parse_double() que, como o nome sugere, passa um conjunto de caracteres para a categoria numérica. Uma função do R Base que poderia fazer o mesmo papel seria as.numeric().\ntibble; para construirmos “tabelas” (tibbles) especiais e visualizarmos o resultado.\ndplyr; para manipulação de dados (agrupar, selecionar, filtrar, arrumar, etc., certas características desejadas nas tibbles)\nstringr; para manipulação de cadeias de caracteres, como frases, texto, símbolos, etc. É bem útil para “limpeza” dos dados coletados numa raspagem da internet (as coisas, geralmente, não vem “arrumadinhas”).\npurrr; para interações. Substitui as ideias das estruturas de repetições (loops) na programação, como for ou while, por exemplo.\nrvest; para raspagem de dados em documentos html. É o principal pacote de nosso minicurso.\nNo que se refere à utilização desses pacotes, podemos escolher algumas arbordagens…\nUma delas é carregar todo o pacote tidyverse na memória do computador. Mas, isso carrega, apenas, uma parte dos pacotes, como vocês podem perceber ao digitarmos:\n\n\nlibrary(tidyverse)\n\n\n── Attaching packages ───────────────────────────── tidyverse 1.3.1 ──\n✓ ggplot2 3.3.5     ✓ purrr   0.3.4\n✓ tibble  3.1.6     ✓ dplyr   1.0.7\n✓ tidyr   1.1.4     ✓ stringr 1.4.0\n✓ readr   2.1.0     ✓ forcats 0.5.1\n── Conflicts ──────────────────────────────── tidyverse_conflicts() ──\nx tidyr::extract()   masks magrittr::extract()\nx dplyr::filter()    masks stats::filter()\nx dplyr::lag()       masks stats::lag()\nx purrr::set_names() masks magrittr::set_names()\n\nNote que foram carregados 8 (oito) pacotes:\n\n\n\nE o rvest não está nessa lista. Então, precisaremos carregá-lo também!\n\n\nlibrary(tidyverse)\nlibrary(rvest)\n\n\n\nEssa é uma abordagem válida e simplifica a escrita dos códigos, tornando-os menos “verbosos”. Uma desvantagem, porém, é que, quando se é iniciante, nem sempre conhecemos de qual pacote pertence determinada função, o que pode atrapalhar os estudos. Além, claro, de carregar a memória do computador com pacotes que não usaremos.\nDessa forma, podemos usar a seguinte abordagem (que usarei no minicurso): não carregaremos o pacote todo (ou seja, não usaremos library(nome-do-pacote)), mas as funções provenientes deles. Para isso, usaremos a seguinte nomenclatura:\n\n\npacote::nome_funcao()\n\n\n\n4.1.1 Uso dos pipes\nA ideia do “pipe” (existem diversas traduções, mas a que me faz comprender a ideia é a de “tubo”, como em uma “encanação”: você conecta as coisas) é, basicamente, escrever o encadeamento do código como pensamos; bem como escrevê-lo em etapas bem delimitadas, trazendo clareza em cada linha de código.\nO tidyverse, por meio do pacote magrittr, disponibiliza o pipe %>%, que pode ser acessado por meio do comando Ctrl + Shift + M.\nPara entendermos um pouco mais sobre o %>%, lembremos das funções compostas. Ao compormos três funções, por exemplo, escrevemos:\n\\[\n  h(g(f(x)))\n\\]\nResolvemos, então, de “dentro” para “fora” da expressão, ou seja, calculamos \\(f(x)\\), depois \\(g(f(x))\\) e, por fim \\(h(g(f(x)))\\).\nMas, nosso raciocínio é mais ou menos assim:\n“pegue o \\(x\\), então\naplique em \\(f()\\), então\naplique em \\(g()\\), então\naplique em \\(h()\\).\nPodemos expressar esse mesmo pensamento usando o %>%, da seguinte forma:\n\n\nx %>% f() %>% g() %>% h()\n\n\n\nOu, na prática, escrevemos assim:\n\n\nx %>% \n  f() %>% \n  g() %>% \n  h()\n\n\n\nOnde \\(x\\) representa, geralmente, algum conjunto de dados (dataset) ou conjunto de caracteres; e, as funções \\(f\\), \\(g\\), \\(h\\) são algumas das funções dos pacotes do tidyverse.\nPor exemplo, suponha que num site leia-se o código html, usando a função read_html(); extraia-se os elementos da tag a, usando a função html_elements(); e, por fim, extraia-se o atributo que armazena os hiperlinks (“href”), com a função html_attr().\nA sequêcia dos códigos ficaria assim:\n\n\nsite |> \n  rvest::read_html() |> \n  rvest::html_elements(\"a\") |> \n  rvest::html_attr(\"href\")\n\n\n\nÔpa! O pipe não era %>%? Por que apareceu |>?\nO pipe introduzido pelo tidyverse foi tão bem aceito, que o próprio R Base decidiu implementar um. O pipe |> é mais rápido do que o %>%, porém, se precisarmos passar dois argumentos numa mesma função, o pipe %>% é mais conveniente.\n\nLogo, podemos usar de forma indiscriminada qualquer dos pipes, desde que seja conveniente para os fins que desejamos. Em especial, nesse minicurso, daremos preferência ao uso do pipe base, |>. Só usaremos o pipe do magrittr, %>%, se houver a necessidade de passarmos dois argumentos numa mesma função.\n\nNo RStudio Cloud, por padrão, vem o pipe %>%. Você não precisa alterar nada para acompanhar o minicurso!\n4.2 Pacotes que usaremos\nVamos, agora, falar um pouco sobre as funções que usaremos nesse minicurso, contextualizando-as em seus respectivos pacotes.\n4.2.1 tibble\nUma tibble é um data frame (do R Base) melhorado. Grosso modo, é uma tabela muito especial. Com ela, podemos organizar os dados de uma forma que facilite a manipulação dos mesmos pelos pacotes do tidyverse e para o processamento no computador. Para quem possuir interesse, o formato da tibble em questão é o tidy, onde cada coluna representa uma variável; cada linha, uma observação; e, em cada célula há apenas uma observação.\nPara nossos fins, basta saber como formar uma tibble e como visualizá-la.\nA função tibble(), do pacote de mesmo nome, tibble, cria a tabela desejada. A estrutura dessa função segue o formato:\n\ntibble::tibble(\n  var_1 = ...,\n  var_2 = ...,\n  ...\n  var_n = ...\n)\n\nPor exemplo, suponha que desejamos construir uma tabela com três variáveis: livro, preco_antigo e preco_novo. Podemos construir uma tibble com:\n\n\ntabela_livros <- tibble::tibble(\n  livro = c(\"Álgebra\", \"Geometria\", \"Análise\"),\n  preco_antigo = c(\"R$ 45.99\", \"R$ 30.50\", \"R$ 80.00\"),\n  preco_novo = c(\"R$ 32.1\", \"R$ 25.50\", \"R$ 72.00\")\n)\n\ntabela_livros\n\n\n# A tibble: 3 × 3\n  livro     preco_antigo preco_novo\n  <chr>     <chr>        <chr>     \n1 Álgebra   R$ 45.99     R$ 32.1   \n2 Geometria R$ 30.50     R$ 25.50  \n3 Análise   R$ 80.00     R$ 72.00  \n\nNotem que a visualização é feita no console do RStudio. Caso queiramos uma visualização mais aprimorada, podemos usar a função view(), da seguinte forma:\n\n\ntabela_livros |> tibble::view()\n\n\n\nA saída assemelha-se a isso (só dá para visualizar no RStuido):\n\n\n\n4.2.2 readr\nO readr possui funções direcionadas para leitura de dados (csv, tsv e fwf). Todavia, existe uma função, que usaremos em determinadas passagens, para transformar a classe dos dados para numérica (numeric ou double).\nO nome dessa função é parse_double().\nVejamos um exemplo.\nSuponha que numa extração de dados da web, os valores de três livros fossem classificados como “character”, mas, obviamente, gostaríamos que eles fossem “numeric”.\n\n\nvalores_web <- c(\"20.2\", \"30.1\", \"23.5\")\n\nclass(valores_web)\n\n\n[1] \"character\"\n\nPara transformar esses valores para dados numéricos, usamos:\n\n\nvalores_num <- valores_web |> \n  readr::parse_double()\n\n\n\nTransformamos e salvamos na variável valores_num. Ao verificarmos a classe, percebemos que os dados passaram a ser numéricos:\n\n\nclass(valores_num)\n\n\n[1] \"numeric\"\n\n4.2.3 dplyr\nO pacote dplyr fornece uma estruturação de funções que seguem uma certa “gramática de manipulação de dados”. Isso fornece um conjunto consistente de “verbos” (os nomes das funções são verbos , em Inglês, que lembram a sua utilidade) que resolvem os desafios mais comuns na manipulação de dados.\nÉ um pacote fabuloso e que precisaríamos de um curso só para falar dele.\nComo o objetivo desse minicurso é sobre Web Scraping, a manipulação dos dados estará contida no processo. Entretanto, manipularemos conjuntos de caracteres e não necessariamente “tibbles”. Portanto, só usaremos algumas poucas funções desse pacote.\nUma delas é a função mutate().\nEm inglês, numa tradução livre, a palavra mutate refere-se a “mudança”, “alteração”, etc. Portanto, usaremos a função mutate() se desejamos fazer uma modificação na tibble (usamos dplyr apenas em tibbles).\nPara exemplificar, considere a seguinte tabela (modificamos a tabela anterior para que as variáveis fossem numéricas):\n\n\ntabela_livros_mod <- tibble::tibble(\n  livro = c(\"Álgebra\", \"Geometria\", \"Análise\"),\n  preco_antigo = c(45.99, 30.50, 80.00),\n  preco_novo = c(32.1, 25.50, 72.00)\n)\n\n\n\nSe quisermos acrescentar uma variável que calcula a diferença entre o “preço novo” (preco_novo) e o “preço antigo” (preco_antigo) precisamos usar o mutate. Ela acrescentará uma nova variável (que daremos o nome diferenca) à tabela_livros_mod.\n\n\ntabela_livros_completa <- tabela_livros_mod |> \n  dplyr::mutate(\n    diferenca = preco_novo - preco_antigo\n  )\n\ntabela_livros_completa\n\n\n# A tibble: 3 × 4\n  livro     preco_antigo preco_novo diferenca\n  <chr>            <dbl>      <dbl>     <dbl>\n1 Álgebra           46.0       32.1     -13.9\n2 Geometria         30.5       25.5      -5  \n3 Análise           80         72        -8  \n\n\nObserve que, para fazer sentido a diferença entre os valores, estes devem ser numéricos!\n\nAgora, suponha que desejamos criar uma nova variável que estabeleça uma “tomada de decisão”. Se o “preço novo” for 30% mais barato do que o “preço antigo”, deseja-se que apareça a mensagem “compre”. Caso contrário, deseja-se que apareça a mensagem “aguarde”.\nPara isso, como podemos notar, precisamos usar uma estrutura “if …, else”, ou seja, “se ocorre ‘condição A’, então ‘faça B’; caso contrário, ‘faça C’”.\nO dplyr fornece uma função para isso: if_else(cond., caso-verdade, caso-contrário).\nNo argumento cond., colocamos a condição desejada;\nNo argumento caso-verdade, colocamos a mensagem caso a condição desejada seja verdadeira;\nNo argumento caso-contrário, colocamos a mensagem caso a condição inicial não seja satisfeita.\nPortanto, o código fica assim:\n\n\ntabela_livros_decisao <- tabela_livros_mod |> \n  dplyr::mutate(\n    decisao = dplyr::if_else(\n      preco_novo <= 0.7 * preco_antigo, \"compre\", \"aguarde\"\n    )\n  )\n\ntabela_livros_decisao\n\n\n# A tibble: 3 × 4\n  livro     preco_antigo preco_novo decisao\n  <chr>            <dbl>      <dbl> <chr>  \n1 Álgebra           46.0       32.1 compre \n2 Geometria         30.5       25.5 aguarde\n3 Análise           80         72   aguarde\n\n4.2.4 rvest\nEsse é o principal pacote que usaremos para o web scraping. Ele será responsável por “ler” os códigos html que cada página dispõe, extraindo os “elementos” que desejamos.\nAbordaremos, de forma direta, algumas das funções desse pacote. Para isso, vamos usar como exemplo o seguinte texto em html:\n\n<html>\n  <head>\n    <title>Web Scraping<\/title>\n  <\/head>\n  <body>\n    <h1>Web Scraping com R<\/h1>\n    <h2>Seção 01: Lista de links<\/h2>\n      <p>Lista de links <\/p>\n      <ul>\n        <li><a href='https://www.mathunion.org/'> União Internaciional de Matemática (IMU)<\/a><\/li>\n        <li><a href='https://sbm.org.br/'> Sociedade Brasileira de Matemática (SBM)<\/a><\/li>\n        <li><a href='https://www.sbmac.org.br/'> Sociedade Brasileira de Matemática Aplicada e Computacional (SBMAC)<\/a><\/li>\n      <\/ul>\n    <h2>Seção 02: Uma imagem<\/h2>\n    <p>Apenas uma imagem de uma Arte Matemática.<\/p>\n    <p align='center'>\n    <img width='200' src='https://www.pinclipart.com/picdir/middle/374-3743859_drawing-geometry-line-art-triangle-vortex-clipart.png'>\n    <\/p>\n    <h2>Seção 03: Uma tabela<\/h2>\n    <p> Aqui vou colocar uma tabela em html.<\/p>\n    <table>\n      <tr>\n        <td><b>nome<\/b><\/td>\n        <td><b>preco_antigo<\/b><\/td>\n        <td><b>preco_novo<\/b><\/td>\n        <td><b>decisao<\/b><\/td>\n      <\/tr>\n      <tr>\n        <td>Álgebra<\/td>\n        <td>R$ 45,99<\/td>\n        <td>R$ 32,10<\/td>\n        <td>compre<\/td>\n      <\/tr>\n      <tr>\n        <td>Geometria<\/td>\n        <td>R$ 30,50<\/td>\n        <td>R$ 25,50<\/td>\n        <td>aguarde<\/td>\n      <\/tr>\n      <tr>\n        <td>Análise<\/td>\n        <td>R$ 80,00<\/td>\n        <td>R$ 72,00<\/td>\n        <td>aguarde<\/td>\n      <\/tr>\n    <\/table>\n  <\/body>\n  \n<\/html>\n\nEle está diponível (o código, não a saída) no link abaixo:\n\n https://git.io/JMTRO \n\nO link dese site foi reduzido, usando o encurtador https://git.io/, do GitHub. Mas, geralmente, os links podem vir bem extensos. Para simplificar essa situação, atribuímos à variável site a url que desejamos analisar (veja que salvamos entre aspas, ou seja, em formato de caracteres):\n\n\nsite <- \"https://git.io/JMTRO\"\n\n\n\nA saída desse código é dada a seguir:\n\n\n\nO primeiro passo é fazer com que o R “leia” (importe) os dados do html para a memória do computador (ou, no caso desse minicurso, para o servidor do RStudio Cloud). Fazemos isso com a função read_html().\nNesse ponto, cabe uma consideração: geralmente extraimos mais de um elemento de uma página web, mas a leitura do html é a mesma. Portanto, salvar esse passo inicial em alguma variável é conveniente. Vamos denominar essa variável por site_base.\nO código fica assim:\n\n\nsite_base <- rvest::read_html(site)\n\nsite_base\n\n\n{html_document}\n<html>\n[1] <head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html; cha ...\n[2] <body>\\n    <h1>Web Scraping com R<\/h1>\\n    <h2>Seção 01: List ...\n\nNotem que o documento possui duas partes: head e body. Como vimos, o que precisamos, encontra-se na tag body. Antes de prosseguirmos, retorne ao código em html e procure encontrar tags como “h1, h2, …”, “a”, “p”, “img”, “table”, etc.\nSuponha que desejamos extrair a tabela dessa página de exemplo. A função para isso é html_table().\n\n\ntabela <- site_base |> \n  rvest::html_table()\n\ntabela\n\n\n[[1]]\n# A tibble: 4 × 4\n  X1        X2           X3         X4     \n  <chr>     <chr>        <chr>      <chr>  \n1 nome      preco_antigo preco_novo decisao\n2 Álgebra   R$ 45,99     R$ 32,10   compre \n3 Geometria R$ 30,50     R$ 25,50   aguarde\n4 Análise   R$ 80,00     R$ 72,00   aguarde\n\nA saída é uma tibble pronta para ser manipulada (você pode estudar sobre o dplyr pra isso)! Mas, o “cabeçalho” dessa tabela não ficou como desejamos: a segunda linha deveria ser esse cabeçalho.\nVocê pode usar o argumento header = TRUE, na função html_table() para que a extração da tabela seja adequada aos nossos fins.\n\n\ntabela <- site_base |> \n  rvest::html_table(header = TRUE)\n\ntabela\n\n\n[[1]]\n# A tibble: 3 × 4\n  nome      preco_antigo preco_novo decisao\n  <chr>     <chr>        <chr>      <chr>  \n1 Álgebra   R$ 45,99     R$ 32,10   compre \n2 Geometria R$ 30,50     R$ 25,50   aguarde\n3 Análise   R$ 80,00     R$ 72,00   aguarde\n\nE se nosso objetivo fosse extair os elementos que contém os links e textos que estão na “Seção 01: …”? Ora, vimos que os links encontram-se na tag “a” (de anchor, ou seja, âncora). Então, nada mais adequado do que extraírmos esse elemento. Para isso, usamos a função html_elements()\n\n\nsite_base |> \n  rvest::html_elements(\"a\")\n\n\n{xml_nodeset (3)}\n[1] <a href=\"https://www.mathunion.org/\"> União Internaciional de M ...\n[2] <a href=\"https://sbm.org.br/\"> Sociedade Brasileira de Matemáti ...\n[3] <a href=\"https://www.sbmac.org.br/\"> Sociedade Brasileira de Ma ...\n\nAqui precisamos decidir … Se quisermos extrair:\na url; usamos a função html_attr(), com o atributo “href”;\no texto; usamos a função html_text2().\n\n\n# extraindo todas as urls -----------------------------------------------------\nsite_base |> \n  rvest::html_elements(\"a\") |> \n  rvest::html_attr(\"href\")\n\n\n[1] \"https://www.mathunion.org/\" \"https://sbm.org.br/\"       \n[3] \"https://www.sbmac.org.br/\" \n\n\n\n# extraindo o texto da tag \"a\" ------------------------------------------------\nsite_base |> \n  rvest::html_elements(\"a\") |> \n  rvest::html_text2()\n\n\n[1] \"União Internaciional de Matemática (IMU)\"                           \n[2] \"Sociedade Brasileira de Matemática (SBM)\"                           \n[3] \"Sociedade Brasileira de Matemática Aplicada e Computacional (SBMAC)\"\n\n4.2.4.1 Sobre o pacote httr\nQuando tentamos extrair informações de alguns sites, certos erros de certificados podem aparecer e os motivos são variádos (veja mais informações aqui).\nPara sanar essa dificuldade, caso apareça algum erro de certificação SSL, devemos colocar, antes da leitura do html, um comando que desativa a verificação dos certificados SSL. O pacote httr fornece a função GET(), para requisição da url e a função config(), para passarmos os parâmetros desejados (que, no nosso caso, seria ssl_verifypeer = FALSE, ou seja, não queremos verificar o certificado SSL).\nEm resumo, coloque assim a linha de código (quando estiver atribuindo à variável site_base):\n\n\nsite_base <- site |> \n  httr::GET(httr::config(ssl_verifypeer = FALSE)) |> \n  rvest::read_html()\n\n\n\nE todo o resto, faça como vimos anteriormente.\n4.2.5 stringr\nEsse pacote é essencial para limpeza dos dados. Sim … os dados não chegam para nós “arrumadinhos”! Ao contrário, na maioria das vezes, os conjuntos de dados possuem caracteres não formatados, ou simplesmente não estão como desejamos organizar.\nDe fato, quando fazemos uma “raspagem de dados”, estamos trabalhando com “fragmentos de textos”. Manipular esses fragmentos é fundamental para que as análises sejam realizadas sem muitos “sustos” (geralmente não sai como desejamos quando, por exemplo, um caractere especial está presente numa extração realizada).\nSeremos diretos ao abordar as funções desse pacote, usadas nesse curso. Antes, é interessante destacar que, tal como no pacote rvest, as funções do pacote stringr seguem determinada estruturação. Por exemplo, a maioria de suas funções começam com str_ (no rvest, a maioria começava com html_).\nPara começarmos, considere a seguinte situação: desejamos extrair o preço dos livros.\nOra, observando o código em html, vemos que a tag que nos ajudará nisso é a tb.\n\n\nsite_base |> \n  rvest::html_elements(\"td\")\n\n\n{xml_nodeset (16)}\n [1] <td><b>nome<\/b><\/td>\n [2] <td><b>preco_antigo<\/b><\/td>\n [3] <td><b>preco_novo<\/b><\/td>\n [4] <td><b>decisao<\/b><\/td>\n [5] <td>Álgebra<\/td>\n [6] <td>R$ 45,99<\/td>\n [7] <td>R$ 32,10<\/td>\n [8] <td>compre<\/td>\n [9] <td>Geometria<\/td>\n[10] <td>R$ 30,50<\/td>\n[11] <td>R$ 25,50<\/td>\n[12] <td>aguarde<\/td>\n[13] <td>Análise<\/td>\n[14] <td>R$ 80,00<\/td>\n[15] <td>R$ 72,00<\/td>\n[16] <td>aguarde<\/td>\n\nBom … tem coisa demais aí. Quero o texto que se encontra entre as tags. Então, usamos:\n\n\nsite_base |> \n  rvest::html_elements(\"td\") |> \n  rvest::html_text2()\n\n\n [1] \"nome\"         \"preco_antigo\" \"preco_novo\"   \"decisao\"     \n [5] \"Álgebra\"      \"R$ 45,99\"     \"R$ 32,10\"     \"compre\"      \n [9] \"Geometria\"    \"R$ 30,50\"     \"R$ 25,50\"     \"aguarde\"     \n[13] \"Análise\"      \"R$ 80,00\"     \"R$ 72,00\"     \"aguarde\"     \n\nAgora não temos mais funções do rvest para nos ajudar. Precisamos manipular esses conjuntos de caracteres com o pacote stringr.\nComo nosso objetivo é extrair os preços, percebemos que há um padrão: todos os preços começam com “R$”. Há uma função no stringr que extrai uma sequência de caracteres que possui determinado padrão. É a função str_subset(). Em seu argumento, colocamos, entre aspas, o padrão que desejamos.\nEm nossa situação, cabe um detalhe: não adiantará (faça o teste) colocarmos str_subset(\"R$\"), pois há um “caractere especial”, a saber, “$”. Esse símbolo do cifrão é usado, no R, para fins específicos e, portanto, devemos “escapar” o código na hora de escolhê-lo. Fazemos isso com duas barras invertidas antes do cifrão. Logo, devemos fazer: str_subset(\"R\\\\$\"). Assim:\n\n\nsite_base |> \n  rvest::html_elements(\"td\") |> \n  rvest::html_text2() |> \n  stringr::str_subset(\"R\\\\$\")\n\n\n[1] \"R$ 45,99\" \"R$ 32,10\" \"R$ 30,50\" \"R$ 25,50\" \"R$ 80,00\" \"R$ 72,00\"\n\nÓtimo! Mas, se desejamos apenas os valores numéricos, precisamos eliminar três caracteres: o “R”, o “$” e o “espaço vazio”!).\nA função str_sub() nos ajudará nessa questão. Sua estrutura é dada por:\n\n\nstringr::str_sub(string, start = ..., end = ...)\n\n\n\nOnde,\nstring, é o conjunto de caracteres que estamos analisando;\nstart = …, é o ponto que iniciaremos a extração. Devemos colocar aqui o número da posição do caractere que desejamos começar!\nend = …, é o ponto que desejamos parar. Se não colocarmos nada, subentende-se que iremos extrair até o final da string.\nPortanto, como queremos eliminar os três primeiros caracteres, vamos iniciar a extração a partir do 4º caractere:\n\n\nsite_base |> \n  rvest::html_elements(\"td\") |> \n  rvest::html_text2() |> \n  stringr::str_subset(\"R\\\\$\") |> \n  stringr::str_sub(4)\n\n\n[1] \"45,99\" \"32,10\" \"30,50\" \"25,50\" \"80,00\" \"72,00\"\n\nMuito bom, não?\nMas, ainda temos um problema: quando trabalhamos com valores numéricos, o separador decimal, por padrão, é o “ponto” e não a “vírgula”. Logo, seria importante subtituírmos todos os pontos por vírgula! Fazemos isso com a função str_replace_all(). Sua estruturação é:\n\n\nstringr::str_replace_all(string, \"padrão\", \"substituição\")\n\n\n\nOnde:\nstring, é o conjunto de caracteres analisado;\npadrão, é o caractere que deverá ser substituido;\nsubstituição, é o novo caractere que desejamos manter por padrão.\nEm nosso caso, desejamos substituir a “vírgula” pelo “ponto”, logo:\n\n\nsite_base |> \n  rvest::html_elements(\"td\") |> \n  rvest::html_text2() |> \n  stringr::str_subset(\"R\\\\$\") |> \n  stringr::str_sub(4) |> \n  stringr::str_replace_all(\",\", \".\")\n\n\n[1] \"45.99\" \"32.10\" \"30.50\" \"25.50\" \"80.00\" \"72.00\"\n\nNote que esse conjunto de dados não está ainda na forma numérica! Sua classe ainda é “character”. Vimos que basta usarmos a função parse_double() do pacote readr:\n\n\nsite_base |> \n  rvest::html_elements(\"td\") |> \n  rvest::html_text2() |> \n  stringr::str_subset(\"R\\\\$\") |> \n  stringr::str_sub(4) |> \n  stringr::str_replace_all(\",\", \".\") |>\n  readr::parse_double()\n\n\n[1] 45.99 32.10 30.50 25.50 80.00 72.00\n\nCom tudo o que vimos, já podemos fazer muitas coisas! Mas, ainda precisamos falar sobre outras importantes funções desse pacote!\nUma situação que frequentemente acontece é colocarmos todas as letras em minúsculas. A função str_to_lower() faz isso tranquilamente!\nPara fins de exemplo, vamos colocar os nomes do texto que se encontra nos elementos “a” em minúsculas. Veja como fica o código:\n\n\nsite_base |> \n  rvest::html_elements(\"a\") |> \n  rvest::html_text2() |>\n  stringr::str_to_lower()\n\n\n[1] \"união internaciional de matemática (imu)\"                           \n[2] \"sociedade brasileira de matemática (sbm)\"                           \n[3] \"sociedade brasileira de matemática aplicada e computacional (sbmac)\"\n\nPara exemplificar as duas últimas funções que usaremos desse pacote, considere o seguinte conjunto de caracteres, denominado livros_nome:\n\n\nlivros_nomes <- c(\n  \"Cálculo em uma Variável Complexa \\n\", \n  \"introdução à álgrebra \\r\", \n  \"Álgebra Linear \\r\"\n)\n\nlivros_nomes \n\n\n[1] \"Cálculo em uma Variável Complexa \\n\"\n[2] \"introdução à álgrebra \\r\"           \n[3] \"Álgebra Linear \\r\"                  \n\nNotem que há caracteres não desejáveis na extração: “\\r” ou “\\n”. Eles quebram a linha, colocando “espaços em branco” depois dos nomes). Para eliminar esses “espaços em branco”, usamos a função str_trim().\n\n\nlivros_nomes |> \n  stringr::str_trim()\n\n\n[1] \"Cálculo em uma Variável Complexa\"\n[2] \"introdução à álgrebra\"           \n[3] \"Álgebra Linear\"                  \n\nAgora, vamos organizar as coisas … Vamos fazer o seguinte, pois retiramos os caracteres indesejados, mas os nomes não estão padronizados:\ncolocar tudo em minúsculas;\nretirar os espaços entre as palavras, substituindo-os por “traços” (-).\nretirar a acentuação (com a função iconv(), do R Base).\nO código fica assim:\n\n\nlivros_nomes |> \n  stringr::str_trim() |> \n  stringr::str_to_lower() |>\n  stringr::str_replace_all(\" \", \"-\") |> \n  base::iconv(to = \"ASCII//TRANSLIT\")\n\n\n[1] \"calculo-em-uma-variavel-complexa\"\n[2] \"introducao-a-algrebra\"           \n[3] \"algebra-linear\"                  \n\nAgora, suponha que desejamos colocar, no início de cada nome organizado de livros, um padrão, por exemplo, “livros-matematica_”. Essa concatenação, ou justaposição de caracteres pode ser feita com a função str_c(). Assim, desejamos algo como: str_c(\"livros-matematica_\", .), onde “.” representa todas as expressões anteriores.\nO código fica assim (note a mudança no pipe, para que seja mais simples mudar o argumento para segunda posição):\n\n\nlivros_nomes |> \n  stringr::str_trim() |> \n  stringr::str_to_lower() |>\n  stringr::str_replace_all(\" \", \"-\") |> \n  base::iconv(to = \"ASCII//TRANSLIT\") %>%\n  stringr::str_c(\"livros-matemática_\", .)\n\n\n[1] \"livros-matemática_calculo-em-uma-variavel-complexa\"\n[2] \"livros-matemática_introducao-a-algrebra\"           \n[3] \"livros-matemática_algebra-linear\"                  \n\nTemos, então, o suficiente do pacote stringr para nosso minicurso!\n4.2.6 purrr\nPor fim, mas não menos importante, precisamos de estruturas de loops. De fato, quando efetuamos uma raspagem de dados que consiste, por exemplo, do download de vários arquivos, a ideia é aplicar uma estrutura de repetição do download de um deles, nos outros arquivos.\nNo R Base existem os “for” e “while” da vida, mas o pacote purrr torna isso tudo mais simples!\nPara entendermos a usabilidade de certas funções do pacote purrr, vamos considerar duas categorias de arquivos: arquivo de texto (como scripts “.R”); e, arquivos binários (como, por exemplo, “.pdf”).\n\n\nlinks_R <- c(\n  \"https://raw.githubusercontent.com/icaro-freire/scripts_exemplos/main/R/funcao_pi-ggplot.R\",\n  \"https://raw.githubusercontent.com/icaro-freire/scripts_exemplos/main/R/funcao_pi.R\",\n  \"https://raw.githubusercontent.com/icaro-freire/scripts_exemplos/main/R/funcao_primos.R\",\n  \"https://raw.githubusercontent.com/icaro-freire/scripts_exemplos/main/R/grafico_apresentacao.R\",\n  \"https://raw.githubusercontent.com/icaro-freire/scripts_exemplos/main/R/pontos-aleatorios_ggplot2.R\"\n)\n\nlinks_pdf <- c(\n  \"https://sbm.org.br/wp-content/uploads/2021/10/Introducao-a-Geometria-Diferencial_Ronaldo-Freire-Lima.pdf\",\n  \"https://sbm.org.br/wp-content/uploads/2021/10/Sistemas-Dinamicos-Lineares-Joao-Socorro-Pinheiro-Ferreira.pdf\",\n  \"https://sbm.org.br/wp-content/uploads/2021/10/Teoria-de-Green-e-Escoamento-de-Poiseuille-Gilberlandio-Dias.pdf\",\n  \"https://sbm.org.br/wp-content/uploads/2021/10/Topicos-na-intersecao-ente-a-Teoria-dos-Grafos-e-Algebra-Abel-Ortiz_Thiago-Moreira.pdf\"\n)\n\n\n\nAntes de começarmos os downloads, vamos organizar nosso espaço de trabalho.\nUma coisa simples é criar um diretório para salvar os arquivos. Podemos fazer isso de muitas formas, mas vamos usar uma função do pacote fs, intitulada, dir_create(). Isso será importante para criarmos uma variável com o mesmo nome do diretório onde salvaremos os arquivos; para que, possamos manipular adequadamente os argumentos da função download.file() dentro do purrr.\nO nome do nosso diretório (pasta) será “download_arquivos”:\n\n\ndownload_arquivos <- fs::dir_create(\"download_arquivos\")\n\n\n\nAgora, vamos relembrar como funciona a função download.file() fazendo o download, por exemplo, do primeiro arquivo “.R” de nossa lista, ou seja, o arquivo do link links_R[1].\nPara isso, precisamos de duas coisas: a url do link, que já sabemos como obter; e o destino junto com o nome desse arquivo, que, aliás, vamos deixar com o nome original. Ora, a url é obtida fazendo links_R[1] e, como o nome desse arquivo é (tem que olhar o nome final do link) “funcao_pi-ggplot.R”, podemos estabelecer o destino do download como: “download_arquivos/funcao_pi-ggplot.R”, ou seja, dentro do diretório “download_arquivos”, vamos salvar um arquivo de extensão “.R”, por nome “funcao_pi-ggplot”. O código ficaria assim:\n\n\ndownload.file(links_R[1], \"download_arquivos/funcao_pi-ggplot.R\")\n\n\n\nNesse ponto, já começamos perceber o quanto seria bom extraírmmos os nomes dos arquivos de forma rápida, sem precisar ver o nome “um por um”; pois, caso nossa lista de link seja consideravelmente maior, ficaria inviável.\nPortanto, ainda falando sobre organização, vamos extrair os nomes dos arquivos acima com o auxílio, mais uma vez, do pacote fs, já que a função path_file() faz esse serviço brilhantemente.\nPodemos extrair o nome original dos arquivos “.R” com o comando:\n\n\nnomes_links_R <- fs::path_file(links_R)\n\nnomes_links_R\n\n\n[1] \"funcao_pi-ggplot.R\"          \"funcao_pi.R\"                \n[3] \"funcao_primos.R\"             \"grafico_apresentacao.R\"     \n[5] \"pontos-aleatorios_ggplot2.R\"\n\nE, para os arquivos “.pdf” assim:\n\n\nnomes_links_pdf <- fs::path_file(links_pdf)\n\nnomes_links_pdf\n\n\n[1] \"Introducao-a-Geometria-Diferencial_Ronaldo-Freire-Lima.pdf\"                            \n[2] \"Sistemas-Dinamicos-Lineares-Joao-Socorro-Pinheiro-Ferreira.pdf\"                        \n[3] \"Teoria-de-Green-e-Escoamento-de-Poiseuille-Gilberlandio-Dias.pdf\"                      \n[4] \"Topicos-na-intersecao-ente-a-Teoria-dos-Grafos-e-Algebra-Abel-Ortiz_Thiago-Moreira.pdf\"\n\nPara nossos fins, vamos considerar até três argumentos da função download.file(), dependendo do seu Sistema Operacional. Quem usa GNU/Linux, só precisa de dois argumentos; mas, quem usa Windows, pode precisar de três argumentos.\nGNU/Linux: dowload.file(url, destfile)\nWindows: dowload.file(url, destfile, mode = \"wb\")\nO GNU/Linux consegue identificar os tipos de arquivos (texto ou binário) de forma automática, mas o Windows não. Para esse últuimo sistema operacional, os arquivos binários precisam ser especificados com o argumento mode = \"wb\".\nPortanto, na parte do download dos arquivos “.pdf”, vamos diferenciar as coisas. Por enquanto, para arquivos de texto, vamos seguir de forma indistinta entre os sistemas operacionais.\nO código abaixo substitui o primeiro download realizado:\n\n\ndownload.file(links_R[1], download_arquivos/nomes_links_R[1])\n\n\n\nOk … Mas, como seria para todos os downloads? É aqui que entra o pacote purrr: a função walk2() nos ajudará nisso! Ela possui a seguinte estruturação:\n\n\npurrr::walk2(arg1, arg2, função)\n\n\n\nOu seja, ela passa os dois argumentos para a função! Em nosso exemplo, a função é download.file e os argumentos são:\narg1 = links_R\narg2 = download_arquivos/nomes_links_R.\nPortando, temos o seguinte código para obtermos o download de todos os arquivos “.R” listados:\n\n\npurrr::walk2(links_R, download_arquivos/nomes_links_R, download.file)\n\n\n\nAgora, para download dos arquivos “.pdf”, caso esteja no GNU/linux, fazemos:\n\n\npurrr::walk2(links_pdf, download_arquivos/nomes_links_pdf, download.file)\n\n\n\nMas, caso esteja no Windows, não poderemos usar mais a função walk2, pois ela APENAS passas dois argumentos; todavia, agora, aparecerá um terceito: mode = \"wb\".\nPara três ou mais parâmetros, a função que estamos procurando é a pwalk(). Ela possui a seguinte estrutura:\n\n\npurrr::pwalk(lista, função)\n\n\n\nNo argumento “lista” criaremos uma lista com todos os argumentos necessários para a função.\nPara nosso exemplo, uma lista adequada seria:\n\n\nlista_args <- list(links_pdf, download_arquivos/nomes_links_pdf, mode = \"wb\")\n\n\n\nPortanto, o download de todos os arquivos “.pdf”, no Windows, fica:\n\n\npurrr::pwalk(lista_args, download.file)\n\n\n\nTodas as considerações acima, capacita-nos à raspagem dos dados!!!\n\n\n\n",
      "last_modified": "2021-12-23T10:03:23-03:00"
    },
    {
      "path": "05_raspagem.html",
      "title": "Raspando os dados com R",
      "description": "Para facilitar nossa vida!\n",
      "author": [],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\n5. Web Scraping como uma ferramenta\n5.1 Ética no Web Scraping\n5.2 Fazendo download de vários arquivos\n5.2.1 Arquivos de texto\n5.2.2 Arquivos binários\n5.2.3 Raspando tabelas\n\n5.3 Construindo uma tabela para tomada de decisão\n5.3.1 Extraindo os nomes dos livros\n5.3.2 Extraindo os preços\n5.3.2 Construindo a tabela\n\n5.4 Raspagem com várias páginas\n\n\n5. Web Scraping como uma ferramenta\nAntes de iniciarmos nossos códigos, nunca é demais salientar que esse texto trata-se de uma introdução. Coletar dados da web pode ser uma tarefa realmente árdua e desafiadora, pois os sites podem dificultar o acesso de diversas formas.\nAbordaremos situações simples, onde o web scraping realmente é usado como uma ferramenta para aumentar a produtividade do professor, reduzindo seu tempo em muitas situações que frequentemente aparecem na vida profissional.\nUma outra coisa impotante, antes de iniciarmos a prática, é sempre termos em mente que nossos códigos são estabelecidos em certo momento temporal, ou seja, o código funciona “naquele momento” e esperamos que continue assim.\nMas, sites podem mudar e, consequentemente, o nosso código pode “quebrar”. Por isso, dependendo da época em que você esteja lendo esse texto, as coisas podem estar bem diferentes. A idéia é você entender os fundamentos e aplicar numa situação particular que deseja.\n5.1 Ética no Web Scraping\nQuando usamos um programa para extrair dados de um site, estamos fazendo requisições ao servidor daquele site. Obviamente, muitas requisições podem tornar lento um site e isso não é desejado por seus mantenedores.\nEssa é uma das razões para que alguns sites restrinjam o acesso em determinada área, ou da totalidade do site!\nPor isso, conhecer as permissões de cada site é importantíssimo numa possível “raspagem” de dados.\n\nSempre leia as permissões do site, antes de iniciar qualquer atividade de web scraping.\n\nUma das formas de sabermos se um site permite a raspagem é verificando os robots.txt.\nPara isso, na url de cada site, ao final da mesma, digite: “/robots.txt”.\nEssa é uma condição necessária, mas não suficiente. Alguns sites colocam restrições não nos robots.txt, mas em alguma seção do mesmo. Por isso, se não aparecer nada no texto do robots.txt, pode ser que o site não o tenha. Então, deve-se procurar informações sobre raspagem de dados no próprio site!\nPor exemplo, no site da ANPMat (Associação Nacional dos Professores de Matemática na Educação Básica), a saber:\n\n https://anpmat.org.br/ \n\nPodemos verificar se “robôs” podem acessá-lo. Para isso, digitamos:\n\n https://anpmat.org.br/robots.txt \n\nA seguinte mensagem aparece:\n\n# XML Sitemap & Google News version 5.2.7 - https://status301.net/wordpress-plugins/xml-sitemap-feed/\nSitemap: https://anpmat.org.br/sitemap.xml\n\nUser-agent: *\nDisallow: /wp-admin/\nAllow: /wp-admin/admin-ajax.php\n\nSitemap: https://anpmat.org.br/wp-sitemap.xml\n\nVeja que a seção “wp-admin” não está hailitada para web scraping.\nUma outra questão, é quando envolve a raspagem de dados em muitas páginas. Mas, o pacote polite pode ser usado junto com o rvest e solucionar esse problema, visto que esse pacote respeitará as requisições feitas em cada site.\nBom … agora vamos à prática!\n5.2 Fazendo download de vários arquivos\nUma das situações que comumente nos deparamos em nossa profissão é fazermos downloads de bons materiais disponíveis gratuitamente na internet. Porém, se a lista de download for relativamente grande, fazer isso manualmente, ou seja, clicar em cada um deles e salvar num determinado local … pode ser tedioso.\nMas … graças a Deus, exite o R!\n5.2.1 Arquivos de texto\nPara exemplificar o dowload de vários arquivos de texto, vamos acessar o link da página do Laboratório de Estatística Computacional – LEC, da UESC. Na seção “Material Didático/R”, estão disponíveis scripts, em R, sobre diversos temas, dentre outras coisas.\n\nO que desejamos fazer? . Essa pergunta sempre deve ser nosso norte, antes de iniciarmos a raspagem dos dados!\n\nNosso objetivo, nesse exemplo, é fazer o download dos 18 arquivos que se encontram na seção “Introdução ao R (tutor: prof. José Cláudio Faria)”, etiquetados como: “CIR.00_apresentação”, “CIR.01_gerenciamentos_pacotes”, …, “CIR.17aplicações”. Como na figura abaixo:\n\n\n\nAgora, vamos atribuir à variável url_uesc o link da url em questão:\n\n\nurl_uesc <- \"https://lec.pro.br/avale-es/r\"\n\n\n\nE, à variável site_uesc o html extraído com a função read_html(), do pacote rvest:\n\n\nsite_uesc <- rvest::read_html(url_uesc)\n\n\n\nEstamos prontos para a manipulação desses dados!\nCom a ajuda do SelectorGadget, selecionamos o elemento que desejamos raspar e, depois, fazemos os ajustes necessários (até ficar em amarelo o que desejamos, da menor forma possível).\nAbaixo, o código mostra que o elemento CCS “li:nth-child(2) h5+ ul a”\n\n\nsite_uesc |> \n  rvest::html_elements(\"li:nth-child(2) h5+ ul a\")\n\n\n{xml_nodeset (18)}\n [1] <a href=\"/download/R/cir/CIR.00_apresentacao.R\">CIR.00_apresen ...\n [2] <a href=\"/download/R/cir/CIR.01_gerenciamento_pacotes.R\">CIR.0 ...\n [3] <a href=\"/download/R/cir/CIR.02_documentacao_ajuda.R\">CIR.02_d ...\n [4] <a href=\"/download/R/cir/CIR.03_operadores.R\">CIR.03_operadore ...\n [5] <a href=\"/download/R/cir/CIR.04_funcoes_elementares.R\">CIR.04_ ...\n [6] <a href=\"/download/R/cir/CIR.05_vetores.R\">CIR.05_vetores<\/a>\n [7] <a href=\"/download/R/cir/CIR.06_matrizes.R\">CIR.06_matrizes<\/a>\n [8] <a href=\"/download/R/cir/CIR.07_dataframes.R\">CIR.07_dataframe ...\n [9] <a href=\"/download/R/cir/CIR.08_arrays.R\">CIR.08_arrays<\/a>\n[10] <a href=\"/download/R/cir/CIR.09_listas.R\">CIR.09_listas<\/a>\n[11] <a href=\"/download/R/cir/CIR.10_tabelas.R\">CIR.10_tabelas<\/a>\n[12] <a href=\"/download/R/cir/CIR.11_condicionais_loops.R\">CIR.11_c ...\n[13] <a href=\"/download/R/cir/CIR.12_funcoes_muito_usadas.R\">CIR.12 ...\n[14] <a href=\"/download/R/cir/CIR.13_funcoes_construindo.R\">CIR.13_ ...\n[15] <a href=\"/download/R/cir/CIR.14_calculo.R\">CIR.14_cálculo<\/a>\n[16] <a href=\"/download/R/cir/CIR.15_importando_exportando.R\">CIR.1 ...\n[17] <a href=\"/download/R/cir/CIR.16_graficos.R\">CIR.16_gráficos<\/a>\n[18] <a href=\"/download/R/cir/CIR.17_aplicacoes.R\">CIR.17_aplicaçõe ...\n\nObviamemte o elemento CCS pode mudar um pouco. Dependenderá muito da seleção que você fez. Por exemplo, se não fossem feitos os ajustes, a tag “a” serviria normalmente. O problema dessa abordadem é que existem muitas outras tags “a” espalhadas pelo site que não nos interessa.\nFeito isso, precisamos extrair desses elementos os links de cada arquivo. O atributto “href” nos dará isso. Então, basta usarmos a função rvest::html_attr(\"href\"):\n\n\nsite_uesc |> \n  rvest::html_elements(\"li:nth-child(2) h5+ ul a\") |> \n  rvest::html_attr(\"href\")\n\n\n [1] \"/download/R/cir/CIR.00_apresentacao.R\"         \n [2] \"/download/R/cir/CIR.01_gerenciamento_pacotes.R\"\n [3] \"/download/R/cir/CIR.02_documentacao_ajuda.R\"   \n [4] \"/download/R/cir/CIR.03_operadores.R\"           \n [5] \"/download/R/cir/CIR.04_funcoes_elementares.R\"  \n [6] \"/download/R/cir/CIR.05_vetores.R\"              \n [7] \"/download/R/cir/CIR.06_matrizes.R\"             \n [8] \"/download/R/cir/CIR.07_dataframes.R\"           \n [9] \"/download/R/cir/CIR.08_arrays.R\"               \n[10] \"/download/R/cir/CIR.09_listas.R\"               \n[11] \"/download/R/cir/CIR.10_tabelas.R\"              \n[12] \"/download/R/cir/CIR.11_condicionais_loops.R\"   \n[13] \"/download/R/cir/CIR.12_funcoes_muito_usadas.R\" \n[14] \"/download/R/cir/CIR.13_funcoes_construindo.R\"  \n[15] \"/download/R/cir/CIR.14_calculo.R\"              \n[16] \"/download/R/cir/CIR.15_importando_exportando.R\"\n[17] \"/download/R/cir/CIR.16_graficos.R\"             \n[18] \"/download/R/cir/CIR.17_aplicacoes.R\"           \n\nAntes de prosseguirmos note um certo “padrão” que aparece nos links desejados. Por exemplo, antes do nome dos arquivos que desejamos extrair, podemos observar a repetição dos caracteres “CIR.”. Isso seria importante se a nossa seleção abrangesse mais arquivos além do exposto. Se isso ocorresse, poderíamos usar uma função do pacote stringr para selecionarmos esse padrão específico: stringr::str_subset(“CIR.”). Mas, como a nossa seleção foi bem exitosa, afinal extraiu o que desejávamos, não usaremos essa função em nosso script.\nNesso momento, também é importante notar que, se clicarmos diretamente em algum dos links desejados, aparecerá uma parte da url, a saber, “https://lec.pro.br”, que não se encontra no conjunto acima listado.\nPara inserirmos essa parte da url, ANTES dos itens da lista acima, usaremos a função str_c(), do pacote stringr. Veja o código abaixo (note que usamos o pipe %>%, pois passaremos o argumento anterior na SEGUNDA posição):\n\n\nsite_uesc |> \n  rvest::html_elements(\"li:nth-child(2) h5+ ul a\") |> \n  rvest::html_attr(\"href\") %>% \n  stringr::str_c(\"https://lec.pro.br\", .)\n\n\n [1] \"https://lec.pro.br/download/R/cir/CIR.00_apresentacao.R\"         \n [2] \"https://lec.pro.br/download/R/cir/CIR.01_gerenciamento_pacotes.R\"\n [3] \"https://lec.pro.br/download/R/cir/CIR.02_documentacao_ajuda.R\"   \n [4] \"https://lec.pro.br/download/R/cir/CIR.03_operadores.R\"           \n [5] \"https://lec.pro.br/download/R/cir/CIR.04_funcoes_elementares.R\"  \n [6] \"https://lec.pro.br/download/R/cir/CIR.05_vetores.R\"              \n [7] \"https://lec.pro.br/download/R/cir/CIR.06_matrizes.R\"             \n [8] \"https://lec.pro.br/download/R/cir/CIR.07_dataframes.R\"           \n [9] \"https://lec.pro.br/download/R/cir/CIR.08_arrays.R\"               \n[10] \"https://lec.pro.br/download/R/cir/CIR.09_listas.R\"               \n[11] \"https://lec.pro.br/download/R/cir/CIR.10_tabelas.R\"              \n[12] \"https://lec.pro.br/download/R/cir/CIR.11_condicionais_loops.R\"   \n[13] \"https://lec.pro.br/download/R/cir/CIR.12_funcoes_muito_usadas.R\" \n[14] \"https://lec.pro.br/download/R/cir/CIR.13_funcoes_construindo.R\"  \n[15] \"https://lec.pro.br/download/R/cir/CIR.14_calculo.R\"              \n[16] \"https://lec.pro.br/download/R/cir/CIR.15_importando_exportando.R\"\n[17] \"https://lec.pro.br/download/R/cir/CIR.16_graficos.R\"             \n[18] \"https://lec.pro.br/download/R/cir/CIR.17_aplicacoes.R\"           \n\nO que precisamos, agora, é fazer o download. Antes, porém, vamos salvar na variável links_uesc a lista extraída acima.\n\n\nlinks_uesc <- site_uesc |> \n  rvest::html_elements(\"li:nth-child(2) h5+ ul a\") |> \n  rvest::html_attr(\"href\") %>% \n  stringr::str_c(\"https://lec.pro.br\", .)\n\n\n\nEstamos quase prontos para fazerrmos o download dos arquivos. Entretanto, vamos organizar as coisas …\nPor exemplo, quando fizermos o download, qual será o nome dos arquivos? Poderíamos criar uma lista com o nome que desejarmos, mas, por hora, vamos deixar os nomes que já estão no final de cada link, pois possui certo padrão:\nCIR.n_nome-do-arquivo.R, onde \\(n\\) varia de 00 até 17.\nMas, como extrair esses nomes?\nPara responder essa pergunta, vamos usar um pacote chamado fs (file system). Ele possui uma função denominada path_file(), que faz justamente o que precisamos. Podemos, então, salvar numa variável nomes_links_uesc tais nomes:\n\n\nnomes_links_uesc <- fs::path_file(links_uesc)\n\n\n\nVimos que a função download.file() precisa de dois argumentos para fazer o download de um arquivo de texto plano: o link e o caminho para salvar o arquivo. Já temos o link e, para não fazermos manualmente a criação de diretórios para salvar os arquivos, vamos usar uma outra função do pacote fs: dir_create(). Nela vamos escrever o caminho onde queremos salvar os arquivos, juntamente com a lista dos nomes.\nComo, nesse minicurso, faremos download de vários arquivos, vamos criar um diretório mais geral, denominado download_arquivos/, onde serão salvos os arquivos dos sites específicos estudados.\nPor exemplo, para os arquivos desse site da UESC, criaremos um subdiretório por nome “arquivos_uesc/”. Vamos atribuir à variável arquivos_uesc todo esse procedimento (note que o nome da variável é o mesmo nome da pasta onde salvaremos os arquivos desse site). O código fica assim:\n\n\narquivos_uesc <- fs::dir_create(\"download_arquivos/arquivos_uesc\")\n\n\n\nPor fim, vamos iterar o download para todos os 18 arquivos, usando o pacote purrr, por meio da função walk2():\n\n\npurrr::walk2(links_uesc, arquivos_uesc/nomes_links_uesc, download.file)\n\n\n\nMaravilha, não?\nVocê pode conferir o script completo abaixo:\n\nScript para download dos arquivos, em R, disponíveis no site da UESC\n\n\n#==============================================================================\n# Raspando material sobre R\n# Ícaro Vidal Freire\n# data de acesso: 2021-12-19\n#==============================================================================\n\n# pacote usado ------------------------------------------------------------\nlibrary(magrittr)\n\n# url do site -------------------------------------------------------------\nurl_uesc <- \"https://lec.pro.br/avale-es/r\"\n\n# site para scraping ------------------------------------------------------\nsite_uesc <- rvest::read_html(url_uesc)\n\n# raspando os materiais ---------------------------------------------------\nlinks_uesc <- site_uesc |> \n  rvest::html_elements(\"li:nth-child(2) h5+ ul a\") |> \n  rvest::html_attr(\"href\") %>% \n  stringr::str_c(\"https://lec.pro.br\", .)\n\n# preparando para download ------------------------------------------------\narquivos_uesc <- fs::dir_create(\"download_arquivos/arquivos_uesc\")\nnomes_links_uesc <- fs::path_file(links_uesc)\n\n# fazendo o download ------------------------------------------------------\npurrr::walk2(links_uesc, arquivos_uesc/nomes_links_uesc, download.file)\n\n#==============================================================================\n\n\n\n5.2.2 Arquivos binários\nNessa seção, vamos fazer o download de arquivos binários no formato pdf. O site onde se encontram esses arquivos é o da Olimpíada Brasileira de Matemética (OBM), especificamente na área da Revista Eureka:\n\n https://www.obm.org.br/revista-eureka/ \n\nNosso objetivo é fazer o download das 42 revistas, no formato pdf, e organizar esses arquivos com nomes seguindo determinado padrão.\nO primeiro passo é fazer a leitura do site. Antes, porém, vamos atribir à variável url_eureka o link do site:\n\n\nurl_eureka <- \"https://www.obm.org.br/revista-eureka/\"\n\n\n\nProsseguimos, então, com a leitura, atribuindo à variável site_eureka seu resultado:\n\n\nsite_eureka <- rvest::read_html(url_eureka)\n\n\n\nFeito isso, precisamos dos elementos que contém os links que desejamos para download. A seleção do CSS ajuda-nos a delimitar as opções adequadamente.\nEntretanto, nesse ponto, perceba uma sutil diferença ao clicar sobre a imagem de algum arquivo do pdf e num pequeno espaço, ao seu lado. Para ser mais claro, vamos considerar o link associado à Revista nº 42:\n\n\n\nObviamente, o link que será extraído não se encontra na tag de “img”. Portanto, devemos clicar num pequeno espaço ao lado dessa imagem de pdf e depois fazermos os ajustes, clicando novamente nos itens que não nos interessa no momento, como por exemplo, nos links do cabeçalho da página.\nCom o passo acima, um elemento CSS possível seria: “#revistas-list a”. Logo, podemos extrair os links assim:\n\n\nsite_eureka |> \n  rvest::html_elements(\"#revistas-list a\") |> \n  rvest::html_attr(\"href\")\n\n\n\n\n [1] \"https://www.obm.org.br/content/uploads/2021/11/Eureka_42.pdf\"        \n [2] \"https://www.obm.org.br/content/uploads/2021/11/revista_eureka_41.pdf\"\n [3] \"https://www.obm.org.br/content/uploads/2017/02/Eureka40.pdf\"         \n [4] \"https://www.obm.org.br/content/uploads/2017/01/eureka39.pdf\"         \n [5] \"https://www.obm.org.br/content/uploads/2017/01/eureka38.pdf\"         \n [6] \"https://www.obm.org.br/content/uploads/2017/01/eureka37.doc\"         \n [7] \"https://www.obm.org.br/content/uploads/2017/01/eureka37.pdf\"         \n [8] \"https://www.obm.org.br/content/uploads/2017/01/eureka36.doc\"         \n [9] \"https://www.obm.org.br/content/uploads/2017/01/eureka36.pdf\"         \n[10] \"https://www.obm.org.br/content/uploads/2017/01/Eureka35.doc\"         \n\nMas, para selecionarmos apenas o formato pdf, usamos: stringr::str_subset(\".pdf\"). Vamos atribuir à variável links_eureka esses procedimentos:\n\n\nlinks_eureka <- site_eureka |> \n  rvest::html_elements(\"#revistas-list a\") |> \n  rvest::html_attr(\"href\") |> \n  stringr::str_subset(\".pdf\")\n\n\n\nSe visualizarmos os nomes desses links, notaremos que não há um padrão único. Para contornar isso, vamos criar uma lista com 42 nomes com o seguinte padrão:\nn_eureka; onde \\(n\\) é um número que varia de 1 a 42.\nUma maneira de criar essa sequência de números é usarmos a função seq(), do R Base:\n\n\nseq(1, 42)\n\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22\n[23] 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42\n\nMas, vamos estabelecer que nosso padrão contenha sempre dois dígitos. Então, para os algarísmos de 1 até 9, colocaremos o número 0 (zero) à esquerda deles. Dessa forma, basta aglutinarmos o caractere “0” à sequência seq(1, 9). A função str_c(), do pacote stringr, é adequada para isso:\n\n\nstringr::str_c(\"0\", seq(1, 9))\n\n\n[1] \"01\" \"02\" \"03\" \"04\" \"05\" \"06\" \"07\" \"08\" \"09\"\n\nTodavia, vamos concatenar esse resultado com os números restantes (de 10 a 42), atribuindo à variável index (pois é uma indexação) esse procedimento:\n\n\nindex <- c(stringr::str_c(\"0\", seq(1, 9)), seq(10, 42))\n\n\n\nPortanto, para criarmos a lista com 42 nomes padronizados, vamos aglutinar à indexação o padão “_eureka”, atribuindo à variável nomes_eureka esses procedimentos:\n\n\nnomes_eureka <- stringr::str_c(index, \"_eureka\")\n\nnomes_eureka\n\n\n [1] \"01_eureka\" \"02_eureka\" \"03_eureka\" \"04_eureka\" \"05_eureka\"\n [6] \"06_eureka\" \"07_eureka\" \"08_eureka\" \"09_eureka\" \"10_eureka\"\n[11] \"11_eureka\" \"12_eureka\" \"13_eureka\" \"14_eureka\" \"15_eureka\"\n[16] \"16_eureka\" \"17_eureka\" \"18_eureka\" \"19_eureka\" \"20_eureka\"\n[21] \"21_eureka\" \"22_eureka\" \"23_eureka\" \"24_eureka\" \"25_eureka\"\n[26] \"26_eureka\" \"27_eureka\" \"28_eureka\" \"29_eureka\" \"30_eureka\"\n[31] \"31_eureka\" \"32_eureka\" \"33_eureka\" \"34_eureka\" \"35_eureka\"\n[36] \"36_eureka\" \"37_eureka\" \"38_eureka\" \"39_eureka\" \"40_eureka\"\n[41] \"41_eureka\" \"42_eureka\"\n\nComo já vimos, para criar um subdiretório, por nome “arquivos_eureka”, no diretório download_arquivos, usamos a função dir_create, do pacote fs. Atribuindo esse passo à variável arquivos_eureka, temos:\n\n\narquivos_eureka <- fs::dir_create(\"downloads/arquivos_eureka\")\n\n\n\nEstamos quase aptos a realizar o dowload de tudo! Basta, criarmos a lista de argumentos para os parâmetros da função pwalk():\n\n\neureka_args <- list(links_eureka, arquivos_eureka/nomes_eureka, mode = \"wb\")\n\n\n\nPor fim, podemos iterar esse procedimento para todos os arquivos com:\n\n\npurrr::pwalk(eureka_args, download.file)\n\n\n\nVocê pode conferir o script completo abaixo:\n\nScript para download de arquivos, em pdf, da Revista Eureka\n\n\n#==============================================================================\n# Download das revistas Eureka\n# Ícaro Vidal Freire\n# data de acesso: 2021-11-26\n#==============================================================================\n\n# url do site -------------------------------------------------------------\nurl_eureka <- \"https://www.obm.org.br/revista-eureka/\"\n\n# preparação do site ------------------------------------------------------\nsite_eureka <- rvest::read_html(url_eureka)\n\n# raspagem dos dados ------------------------------------------------------\n## extraindo links\nlinks_eureka <- site_eureka |> \n  rvest::html_elements(\"#revistas-list a\") |> \n  rvest::html_attr(\"href\") |> \n  stringr::str_subset(\".pdf\")\n\n## modificando os nomes\nindex <- c(stringr::str_c(\"0\", seq(1, 9)), seq(10, 42))\nnomes_eureka <- stringr::str_c(index, \"_eureka\")\n\n## criando os diretórios e caminhos\narquivos_eureka <- fs::dir_create(\"downloads/arquivos_eureka\")\n\n## preparando os argumentos para download\neureka_args <- list(links_eureka, arquivos_eureka/nomes_eureka, mode = \"wb\")\n\n# fazendo os downloads ----------------------------------------------------\npurrr::pwalk(eureka_args, download.file)\n\n#==============================================================================\n\n\n\n5.2.3 Raspando tabelas\nA função do pacote rvest para raspar uma tabela é html_table().\nPara exemplificarmos seu uso, consideremos a seguinte página da Wikipédia sobre a linguagem de programação R:\n\n https://pt.wikipedia.org/wiki/R_(linguagem_de_programa%C3%A7%C3%A3o) \n\nAparentemente, a única tabela existente na página é a da seção “Versão”.\nDiretamente, poderíamos fazer:\n\n\n# url do site -----------------------------------------------------------------\nurl_wiki <- \"https://pt.wikipedia.org/wiki/R_(linguagem_de_programa%C3%A7%C3%A3o)\"\n\n# leitura do site -------------------------------------------------------------\nsite_wiki <- rvest::read_html(url_wiki)\n\n# extração da tabela ----------------------------------------------------------\ntabelas <- rvest::html_table(site_wiki)\n\n# exibindo o conteúdo ---------------------------------------------------------\ntabelas\n\n\n[[1]]\n# A tibble: 1 × 2\n  X1    X2                                                            \n  <lgl> <chr>                                                         \n1 NA    As referências deste artigo necessitam de formatação. Por fav…\n\n[[2]]\n# A tibble: 1 × 2\n  X1    X2                                                            \n  <lgl> <chr>                                                         \n1 NA    Este artigo carece de reciclagem de acordo com o  livro de es…\n\n[[3]]\n# A tibble: 1 × 2\n  X1    X2                                                            \n  <lgl> <chr>                                                         \n1 NA    Esta página cita fontes, mas estas não cobrem todo o conteúdo…\n\n[[4]]\n# A tibble: 11 × 2\n   R                   R                                              \n   <chr>               <chr>                                          \n 1 \"\"                  \"\"                                             \n 2 \"Paradigma\"         \"multi-paradigma: sequencialização, orientado …\n 3 \"Surgido em\"        \"1993[1]\"                                      \n 4 \"Última versão\"     \"4.1.0[2](18 de maio de 2021)\"                 \n 5 \"Criado por\"        \"Ross Ihaka e Robert Gentleman\"                \n 6 \"Estilo de tipagem\" \"Fraca\"                                        \n 7 \"Dialetos:\"         \"Microsoft R\"                                  \n 8 \"Influenciada por\"  \"S, Common Lisp, Scheme, Haskell\"              \n 9 \"Influenciou\"       \"Julia\"                                        \n10 \"Licença:\"          \"GPL\"                                          \n11 \"Página oficial\"    \"www.r-project.org\"                            \n\n[[5]]\n# A tibble: 13 × 3\n   Versão Data         Descrição                                      \n   <chr>  <chr>        <chr>                                          \n 1 0.16   \"\"           \"Essa foi a última versão alpha desenvolvida p…\n 2 0.49   \"1997-04-23\" \"Esse é o código fonte mais antigo disponível …\n 3 0.60   \"1997-12-05\" \"R se torna parte do Projeto GNU. O código pas…\n 4 0.65.1 \"1999-10-07\" \"Primeiras versões das funções update.packages…\n 5 1.0    \"2000-02-29\" \"Considerada pelos desenvolvedores como estáve…\n 6 1.4    \"2001-12-19\" \"Métodos S4 foram introduzidos e a primeira ve…\n 7 2.0    \"2004-10-04\" \"Introduzido lazy loading, que permite carrega…\n 8 2.1    \"2005-04-18\" \"Suporte para UTF-8 e esforços iniciais para l…\n 9 2.11   \"2010-04-22\" \"Suporte para sistemas Windows de 64 bits.\"    \n10 2.13   \"2011-04-14\" \"Adicionada uma nova função ao compilador que …\n11 2.14   \"2011-10-31\" \"Adicionados namespaces mandatórios para os pa…\n12 2.15   \"2012-03-30\" \"Novas funções de balanceamento de carga. Velo…\n13 3.0    \"2013-04-03\" \"Suporte para indexadores numéricos de valor 2…\n\n[[6]]\n# A tibble: 1 × 2\n  X1                     X2                                           \n  <chr>                  <chr>                                        \n1 Controle de autoridade \": Q206904\\nFramalibre: r\\nGND: 4705956-4\\nL…\n\n[[7]]\n# A tibble: 3 × 2\n  `vdeSoftware para análise numéric… `vdeSoftware para análise numéri…\n  <chr>                              <chr>                            \n1 \"Software livre\"                   \"Advanced Simulation Library\\nAD…\n2 \"Software não-livre\"               \"DADiSP\\nGAUSS\\nLabVIEW\\nMaple\\n…\n3 \"Lista de programas para análise … \"Lista de programas para análise…\n\n[[8]]\n# A tibble: 5 × 3\n  `vdeProjeto GNU` `vdeProjeto GNU`                   `vdeProjeto GNU`\n  <chr>            <chr>                              <lgl>           \n1 História         \"Manifesto GNU\\nFree Software Fou… NA              \n2 Licenças         \"GNU General Public License\\nGNU … NA              \n3 Software         \"GNU (variantes)\\nHurd\\nLinux-lib… NA              \n4 Porta-Vozes      \"Alexandre Oliva\\nBenjamin Mako H… NA              \n5 Outros assuntos  \"Controvérsia quanto à nomenclatu… NA              \n\n[[9]]\n# A tibble: 3 × 2\n  `vdeLinguagens de programação`     `vdeLinguagens de programação`   \n  <chr>                              <chr>                            \n1 \"Esotéricas ·  Comparação ·  Hist… \"Esotéricas ·  Comparação ·  His…\n2 \"Ada\\nAssembly (ASM)\\nBASIC\\nC\\nC… \"Ada\\nAssembly (ASM)\\nBASIC\\nC\\n…\n3 \"Categoria ·  Lista\"               \"Categoria ·  Lista\"             \n\nPara nossa surpresa há 9 tabelas nessa página! Quem a escreveu usou do formato da tabela para organização das informações, mas em apenas uma colocou elementos característicos de um quadro.\nVeja que a classe do objeto “tabelas” é uma lista:\n\n\nclass(tabelas)\n\n\n[1] \"list\"\n\nAinda analisando essa lista, percebemos que a tabela que desejamos encontra-se na 5º posição. Portanto, podemos selecioná-la da seguinte maneira:\n\n\ntabela_wiki <- tabelas[[5]]\n\ntabela_wiki\n\n\n# A tibble: 13 × 3\n   Versão Data         Descrição                                      \n   <chr>  <chr>        <chr>                                          \n 1 0.16   \"\"           \"Essa foi a última versão alpha desenvolvida p…\n 2 0.49   \"1997-04-23\" \"Esse é o código fonte mais antigo disponível …\n 3 0.60   \"1997-12-05\" \"R se torna parte do Projeto GNU. O código pas…\n 4 0.65.1 \"1999-10-07\" \"Primeiras versões das funções update.packages…\n 5 1.0    \"2000-02-29\" \"Considerada pelos desenvolvedores como estáve…\n 6 1.4    \"2001-12-19\" \"Métodos S4 foram introduzidos e a primeira ve…\n 7 2.0    \"2004-10-04\" \"Introduzido lazy loading, que permite carrega…\n 8 2.1    \"2005-04-18\" \"Suporte para UTF-8 e esforços iniciais para l…\n 9 2.11   \"2010-04-22\" \"Suporte para sistemas Windows de 64 bits.\"    \n10 2.13   \"2011-04-14\" \"Adicionada uma nova função ao compilador que …\n11 2.14   \"2011-10-31\" \"Adicionados namespaces mandatórios para os pa…\n12 2.15   \"2012-03-30\" \"Novas funções de balanceamento de carga. Velo…\n13 3.0    \"2013-04-03\" \"Suporte para indexadores numéricos de valor 2…\n\nPoderíamos simplificar os passos da seguinte forma:\n\n\n# carregando pacote -----------------------------------------------------------\nlibrary(magrittr)\n\n# url do site -----------------------------------------------------------------\nurl_wki <- \"https://pt.wikipedia.org/wiki/R_(linguagem_de_programa%C3%A7%C3%A3o)\"\n\n# lendo e raspando os dados ---------------------------------------------------\ntabela_wiki <- url_wki |> \n  rvest::read_html() |> \n  rvest::html_table() %>%\n  .[[5]]\n\n# exibindo a tabela -----------------------------------------------------------\ntabela_wiki\n\n\n\n5.3 Construindo uma tabela para tomada de decisão\nNo site da livraria da USP, na seção “ASSUNTOS”, ao escolhermos “Matemática”, somos direcionados para essa página:\n\n https://www.edusp.com.br/loja/assuntos/21/matematica \n\nHá uma lista de 19 livros (acesso em 23/12/2021), mas suponha que nosso objetivo seja acompanhar a variação do preço de três deles:\nNúmeros: Uma Introdução à Matemática;\nUm Poeta, um Matemático e um Físico;\nProgramação Matemática para Otimização de Processos.\nAinda mais: se o desconto dado pelo site for igual ou superior a 20% do valor do livro, gostaríamos que uma tabela fosse exibida com alguma informação direta, como por exemplo, “compre”; e, caso contrário, “aguarde”.\nPortanto, precisamos extrair:\nOs nomes dos livros;\nOs preços que estão na categoria “De …”;\nOs preços que estão na categoria “Por …”;\nUma lista espacífica que desejamos comparar (a nossa lista com os três livros);\nAlguma condição para devolver os termos “compre” ou “aguarde.\nVamos fazer isso passo a passo, mas antes de começarmos, é importante organizarmos as coisas:\n\n\n# url do site -----------------------------------------------------------------\nurl_usp <- \"https://www.edusp.com.br/loja/assuntos/21/matematica\"\n\n# lendo o site ----------------------------------------------------------------\nsite_usp <- url_usp |> \n  rvest::read_html()\n\n\n\n\nError in open.connection(x, \"rb\") : \n  SSL certificate problem: unable to get local issuer certificate\n\nNotem que houve um problema de Certificado de SSL. Vimos que, para contornar isso, retiramos a verificação do certificado (ssl_verifypeer = FALSE) com a função config(), do pacote httr, dentro da função GET(), do mesmo pacote; sendo tudo isso ANTES do read_html():\n\n\n# url do site -----------------------------------------------------------------\nurl_usp <- \"https://www.edusp.com.br/loja/assuntos/21/matematica\"\n\n# lendo o site ----------------------------------------------------------------\nsite_usp <- url_usp |> \n  httr::GET(httr::config(ssl_verifypeer = FALSE)) |> \n  rvest::read_html()\n\n\n\n5.3.1 Extraindo os nomes dos livros\nUtilizando o SelectorGadget, clicamos sobre um dos títulos do livro e fazemos os ajustes necessários (aparecerão elementos no rodapé da página do site que não são convenientes). Com isso, um possível CSS é: “#dvProdutos p”.\n\n\nsite_usp |> \n  rvest::html_elements(\"#dvProdutos p\")\n\n\n{xml_nodeset (19)}\n [1] <p>\\r\\n                                    Amostragem Probabil ...\n [2] <p>\\r\\n                                    Bioestatística em O ...\n [3] <p>\\r\\n                                    Cálculo em uma Vari ...\n [4] <p>\\r\\n                                    Cálculo Integral Av ...\n [5] <p>\\r\\n                                    Curso de Álgebra Li ...\n [6] <p>\\r\\n                                    Ética em Computação ...\n [7] <p>\\r\\n                                    Introdução à Física ...\n [8] <p>\\r\\n                                    Introdução à Mecâni ...\n [9] <p>\\r\\n                                    Lógica Matemática<\/p>\n[10] <p>\\r\\n                                    Noções de Probabili ...\n[11] <p>\\r\\n                                    Números: Uma Introd ...\n[12] <p>\\r\\n                                    Ondas e Ondaletas:  ...\n[13] <p>\\r\\n                                    Poeta, um Matemátic ...\n[14] <p>\\r\\n                                    Probabilidade e Var ...\n[15] <p>\\r\\n                                    Probabilidade: Um C ...\n[16] <p>\\r\\n                                    Programação Matemát ...\n[17] <p>\\r\\n                                    Técnicas Computacio ...\n[18] <p>\\r\\n                                    Topologia Geométric ...\n[19] <p>\\r\\n                                    Uma Variável Comple ...\n\nQueremos extrair os nomes dos livros. Logo, interessa-nos o texto entre a tag <p>; e, para isso, usamos a função text2():\n\n\nsite_usp |> \n  rvest::html_elements(\"#dvProdutos p\") |> \n  rvest::html_text2()\n\n\n [1] \"\\r Amostragem Probabilística: Um Curso...\"   \n [2] \"\\r Bioestatística em Outras Palavras\"        \n [3] \"\\r Cálculo em uma Variável Real\"             \n [4] \"\\r Cálculo Integral Avançado\"                \n [5] \"\\r Curso de Álgebra Linear, Um\"              \n [6] \"\\r Ética em Computação\"                      \n [7] \"\\r Introdução à Física Estatística\"          \n [8] \"\\r Introdução à Mecânica Clássica\"           \n [9] \"\\r Lógica Matemática\"                        \n[10] \"\\r Noções de Probabilidade e Estatística\"    \n[11] \"\\r Números: Uma Introdução à Matemática\"     \n[12] \"\\r Ondas e Ondaletas: Da Análise de...\"      \n[13] \"\\r Poeta, um Matemático e um Físico, Um:...\" \n[14] \"\\r Probabilidade e Variáveis Aleatórias\"     \n[15] \"\\r Probabilidade: Um Curso Introdutório\"     \n[16] \"\\r Programação Matemática para Otimização...\"\n[17] \"\\r Técnicas Computacionais para Dinâmica...\" \n[18] \"\\r Topologia Geométrica para Inquietos\"      \n[19] \"\\r Uma Variável Complexa: Teoria e...\"       \n\nE, para retirar os caracteres indesejados de espaçamento, usamos a função str_trim(), do pacote stringr:\n\n\nsite_usp |> \n  rvest::html_elements(\"#dvProdutos p\") |> \n  rvest::html_text2() |> \n  stringr::str_trim()\n\n\n [1] \"Amostragem Probabilística: Um Curso...\"   \n [2] \"Bioestatística em Outras Palavras\"        \n [3] \"Cálculo em uma Variável Real\"             \n [4] \"Cálculo Integral Avançado\"                \n [5] \"Curso de Álgebra Linear, Um\"              \n [6] \"Ética em Computação\"                      \n [7] \"Introdução à Física Estatística\"          \n [8] \"Introdução à Mecânica Clássica\"           \n [9] \"Lógica Matemática\"                        \n[10] \"Noções de Probabilidade e Estatística\"    \n[11] \"Números: Uma Introdução à Matemática\"     \n[12] \"Ondas e Ondaletas: Da Análise de...\"      \n[13] \"Poeta, um Matemático e um Físico, Um:...\" \n[14] \"Probabilidade e Variáveis Aleatórias\"     \n[15] \"Probabilidade: Um Curso Introdutório\"     \n[16] \"Programação Matemática para Otimização...\"\n[17] \"Técnicas Computacionais para Dinâmica...\" \n[18] \"Topologia Geométrica para Inquietos\"      \n[19] \"Uma Variável Complexa: Teoria e...\"       \n\nVamos salvar tudoo isso na variável nomes_livros:\n\n\nnomes_livros <- site_usp |> \n  rvest::html_elements(\"#dvProdutos p\") |> \n  rvest::html_text2() |> \n  stringr::str_trim()\n\n\n\n5.3.2 Extraindo os preços\nPara extração dos preços, lembremos que são duas categorias:\n“De …”; que substituiremos por preco_antigo.\n“Por …”; que substituiremos por preco_desconto.\n5.3.2.1 Preço antigo\nUtilizando o SelectorGadget, ao clicarmos na região onde há um “traço” no preço, encontramos o seguinte elemento CSS: “strike”.\n\n\nsite_usp |> \n  rvest::html_elements(\"strike\")\n\n\n{xml_nodeset (19)}\n [1] <strike>R$ 40,00<\/strike>\n [2] <strike>R$ 66,00<\/strike>\n [3] <strike>R$ 74,00<\/strike>\n [4] <strike>R$ 52,00<\/strike>\n [5] <strike>R$ 45,00<\/strike>\n [6] <strike>R$ 40,00<\/strike>\n [7] <strike>R$ 80,00<\/strike>\n [8] <strike>R$ 78,00<\/strike>\n [9] <strike>R$ 34,00<\/strike>\n[10] <strike>R$ 52,00<\/strike>\n[11] <strike>R$ 42,00<\/strike>\n[12] <strike>R$ 44,00<\/strike>\n[13] <strike>R$ 30,00<\/strike>\n[14] <strike>R$ 50,00<\/strike>\n[15] <strike>R$ 52,00<\/strike>\n[16] <strike>R$ 44,00<\/strike>\n[17] <strike>R$ 74,00<\/strike>\n[18] <strike>R$ 36,00<\/strike>\n[19] <strike>R$ 38,00<\/strike>\n\nRetirando o texto dessa tag, temos:\n\n\nsite_usp |> \n  rvest::html_elements(\"strike\") |> \n  rvest::html_text2()\n\n\n [1] \"R$ 40,00\" \"R$ 66,00\" \"R$ 74,00\" \"R$ 52,00\" \"R$ 45,00\" \"R$ 40,00\"\n [7] \"R$ 80,00\" \"R$ 78,00\" \"R$ 34,00\" \"R$ 52,00\" \"R$ 42,00\" \"R$ 44,00\"\n[13] \"R$ 30,00\" \"R$ 50,00\" \"R$ 52,00\" \"R$ 44,00\" \"R$ 74,00\" \"R$ 36,00\"\n[19] \"R$ 38,00\"\n\nObviamente, queremos apenas os valores numéricos, visto que ainda vamos operar com os mesmos para criarmos condições para tomada de decisão. Assim, observando o padrão, interessa-nos os elementos depois do 3ª caractere, ou seja, a partir do 4º caractere. A função str_sub(), do pacote stringr faz isso perfeitamente:\n\n\nsite_usp |> \n  rvest::html_elements(\"strike\") |> \n  rvest::html_text2() |> \n  stringr::str_sub(4)\n\n\n [1] \"40,00\" \"66,00\" \"74,00\" \"52,00\" \"45,00\" \"40,00\" \"80,00\" \"78,00\"\n [9] \"34,00\" \"52,00\" \"42,00\" \"44,00\" \"30,00\" \"50,00\" \"52,00\" \"44,00\"\n[17] \"74,00\" \"36,00\" \"38,00\"\n\nAgora, sabemos que o R identifica o ponto como separador decimal. Logo, devemos substituir a “vírgula” pelo “ponto”. Para isso, usamo a função str_replace_all():\n\n\nsite_usp |> \n  rvest::html_elements(\"strike\") |> \n  rvest::html_text2() |> \n  stringr::str_sub(4) |> \n  stringr::str_replace_all(\",\", \".\")\n\n\n [1] \"40.00\" \"66.00\" \"74.00\" \"52.00\" \"45.00\" \"40.00\" \"80.00\" \"78.00\"\n [9] \"34.00\" \"52.00\" \"42.00\" \"44.00\" \"30.00\" \"50.00\" \"52.00\" \"44.00\"\n[17] \"74.00\" \"36.00\" \"38.00\"\n\nMas, ainda temos um conjundo de “caracteres” (character) e não números (numeric). Para extrairmos apenas os números, podemos usar a função parse_double(), do pacote readr:\n\n\nsite_usp |> \n  rvest::html_elements(\"strike\") |> \n  rvest::html_text2() |> \n  stringr::str_sub(4) |> \n  stringr::str_replace_all(\",\", \".\") |> \n  readr::parse_double()\n\n\n [1] 40 66 74 52 45 40 80 78 34 52 42 44 30 50 52 44 74 36 38\n\nVamos atribuir à variável preco_antigo esses códigos:\n\n\npreco_antigo <- site_usp |> \n  rvest::html_elements(\"strike\") |> \n  rvest::html_text2() |> \n  stringr::str_sub(4) |> \n  stringr::str_replace_all(\",\", \".\") |> \n  readr::parse_double()\n\n\n\n5.3.2.2 Preço antigo\nProcedendo de forma análoga, podemos extrair o preco_desconto:\n\n\npreco_desconto <- site_usp |> \n  rvest::html_elements(\"h2+ h2\") |>     # elemento CSS\n  rvest::html_text2() |>                # extração do conteúdo (texto)\n  stringr::str_trim() |>                # eliminando espaços indesejáveis\n  stringr::str_sub(8) |>                # extraindo a partir do 8º caractere\n  stringr::str_replace(\",\", \".\") |>     # substituindo 'virgula' por 'ponto'\n  readr::parse_double()                 # transformando 'character' para 'numeric'\n\n\n\n5.3.2 Construindo a tabela\n5.4 Raspagem com várias páginas\n\n\n\n",
      "last_modified": "2021-12-24T13:09:09-03:00"
    },
    {
      "path": "index.html",
      "title": "Raspando os Dados da Web",
      "description": "Uma Indrodução ao R\n",
      "author": [
        {
          "name": "Ícaro Vidal Freire",
          "url": {}
        }
      ],
      "contents": "\nObjetivo do Minicurso\nAntes de falarmos formalmente sobre o objetivo do Minicurso, considereremos as seguintes situações:\n\n1º Situação\nEncontramos um site que disponibiliza, gratuitamente, vários materiais que julgamos importantes armazenar também em nosso computador — para o caso de usá-los quando não estiver com internet disponível, por exemplo.\nVamos supor que são 30 arquivos no formato pdf.\nO que faríamos?\nClicaríamos em cada um deles e faríamos download desses arquivos manualmente? Bom, essa é uma opção válida, mas seria muito mais produtivo e elegante, se pudéssemos fazer o download de forma automatizada, não? Todos os 30 arquivos, de “uma só vez”, salvos num diretório (pasta) específico de nosso computador! Seria uma maravilha, não?\n2º Situação\nSuponha, agora, que desejamos comprar alguns livros de um site que sempre oferece promoções interessantes. Mas, previamente estabelecemos que a compra seria realizada se esses livros estivessem com 30% de desconto.\nObviamente poderíamos entrar no site todos os dias; procurar um a um; e, calcularmos se o desconto aconteceu. Mas, e se criássemos um script (uma sequência, encadeada, de comandos para que um programa execute uma ação) que possui como resultado uma tabela com os preços diários exibidos, já com o desconto efetivado, para que pudéssemos tomar uma decisão rapidamente?\n\nFormalizando o objetivo\nEssas duas situações são comumente encontradas no trabalho do professor ou estudante.\nO objetivo desse minicurso é oferecer ferramentas para que, pelo menos, as duas situações, acima expostas, possam ser resolvidas de maneira racional, rápida e prazerosa.\nPara isso, introduziremos uma linguagem (e ambiente) de programação, denominada R. Na realidade, nosso foco será voltado a certos pacotes desenvolvidos que unificam uma estrutura de linguagem em R. Veremos que tal característica facilita muito o aprendizado das funções e potencialidades do R.\n\nNão é objetivo desse minicurso uma exaustiva análise ou exibição de funções, estruturas, ou objetos em R.\n\nApenas tangenciaremos alguns pacotes para usarmos as funções neles contidas, necessárias para solucionarmos as duas situações expostas no início desse texto. Logo, será uma Introdução ao R, mostrando que, dentre outras coisas, podemos fazer web scrape (“raspagem” de dados na internet) de maneira bem intuitiva e racional, ao mesmo tempo!\nPara isso, dividimos esse minicurso em três dias, para que a sedimentação das informações seja adequada e, assim, o minicurso seja usufruído da melhor maneira possível.\nEspero que gostem!\nEstruturação do Minicurso\n\n1º Dia\nApresentação dos objetivos, da plataforma RStudio Cloud e da metodologia;\nO que é Webscraping?\nTangenciando a estrutura de um arquivo html;\nUsando o SelectorGadget;\nINTERVALO (~ 15 min)\nVendo como funciona na prática!\nDownload simultâneo de vários arquivos de texto plano\n\n2º Dia\nIntrodução ao R\nO que é o R?\nObjetos e Funções Básicas no R\n\nINTERVALO (~ 15 min)\nAlgo sobre o Tidyverse\ntibble, dplyr;\nstringr;\nrvest\n\nDuas funções do pacote fs (File System)\n3º Dia\nDownload simultâneo de vários arquivos binários (pdf);\nDownload e limpeza de vários arquivos binários (pdf);\nMontando uma lista de preços para tomada de decisão;\nRaspagem de dados em mais de uma página.\n\n\n\n\n",
      "last_modified": "2021-12-23T10:03:23-03:00"
    }
  ],
  "collections": []
}
